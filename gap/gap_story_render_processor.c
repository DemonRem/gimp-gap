/* gap_story_render_processor.c
 *
 *
 *  GAP storyboard rendering processor.
 *
 *  GAP video encoder tool procedures for STORYBOARD file based video encoding
 *  This module is the Storyboard processor that reads instructions from the storyboard
 *  file, fetches input frames, and renders composite video frames
 *  according to the instructions in the storyboard file.
 *
 *  The storyboard processor is typically used to:
 *   - check storyboard syntax and deliver information (number of total frames)
 *     for the master encoder dialog.
 *   - render the composite video frame at specified master frame number
 *     (is called as frame fetching utility by all encoders)
 *
 *   The storyboard processor provides fuctionality to mix audiodata,
 *   this is usually done in the master encoder dialog (before starting the selected encoder)
 *
 * Copyright (C) 2006 Wolfgang Hofer <hof@gimp.org>
 *
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
 */

/*
 * 2006.06.25  hof  - created (moved stuff from the former gap_gve_story modules to this  new module)
 *                  - new features: 
 *                       use shadow tracks, (implicite) generated by the new overlap attribute
 *                       normal track numbers are         1, 3, 5, 7
 *                       corresponding shadow tracks are  0, 2, 4, 6   (shadow = normal -1)
 *                  - support video frame flipping (hor/vertical)
 *
 */
 
#include <config.h>

/* SYTEM (UNIX) includes */
#include <stdlib.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <math.h>
#include <errno.h>

#include <dirent.h>


#include <glib/gstdio.h>



/* GIMP includes */
#include "gtk/gtk.h"
#include "gap-intl.h"
#include "libgimp/gimp.h"


#include "gap_libgimpgap.h"
#include "gap_lib_common_defs.h"
#include "gap_file_util.h"
#include "gap_audio_util.h"
#include "gap_audio_wav.h"
#include "gap_vid_api.h"
#include "gap_story_file.h"
#include "gap_layer_copy.h"
#include "gap_story_render_audio.h"
#include "gap_story_render_processor.h"

/*************************************************************
 *         STORYBOARD FUNCTIONS                              *
 *************************************************************
 */

#define MAX_IMG_CACHE_ELEMENTS 6

extern int gap_debug;  /* 1 == print debug infos , 0 dont print debug infos */



static GapStoryRenderImageCache *global_imcache = NULL;
static gint32 global_monitor_image_id = -1;
static gint32 global_monitor_display_id = -1;


static void     p_frame_backup_save(  char *key
                  , gint32 image_id
                  , gint32 layer_id
                  , gint32  master_frame_nr
                  , gboolean multilayer
                  );
static void     p_debug_dup_image(gint32 image_id);
static void     p_encoding_monitor(  char *key
                  , gint32 image_id
                  , gint32 layer_id
                  , gint32  master_frame_nr
                  );
static GapStoryRenderErrors * p_new_stb_error(void);
static void     p_init_stb_error(GapStoryRenderErrors *sterr);
static void     p_free_stb_error(GapStoryRenderErrors *sterr);
static void     p_set_stb_error(GapStoryRenderErrors *sterr, char *errtext);
static void     p_drop_image_cache_elem1(GapStoryRenderImageCache *imcache);
static gint32   p_load_cache_image( char* filename);
static void     p_find_min_max_vid_tracknumbers(GapStoryRenderFrameRangeElem *frn_list
                             , gint32 *lowest_tracknr
                             , gint32 *highest_tracknr
                             );
static void     p_step_attribute(gint32 frames_handled
                 ,gdouble *from_val
                 ,gdouble *to_val
                 ,gint32  *dur
                 );
static gdouble  p_step_attribute_read(gint32 frame_step
                 ,gdouble from_val
                 ,gdouble to_val
                 ,gint32  dur
                 );
static gdouble  p_step_attribute_read(gint32 frame_step
                 ,gdouble from_val
                 ,gdouble to_val
                 ,gint32  dur
                 );
static char *   p_fetch_framename   (GapStoryRenderFrameRangeElem *frn_list
                            , gint32 master_frame_nr                   /* starts at 1 */
                            , gint32 track
                            , GapStoryRenderFrameType *frn_type
                            , char **filtermacro_file
                            , gint32   *localframe_index  /* used only for ANIMIMAGE and videoclip, -1 for all other types */
                            , gint32   *local_stepcount   /* nth frame within this clip, starts with 0 */
                            , gboolean *keep_proportions
                            , gboolean *fit_width
                            , gboolean *fit_height
                            , gdouble  *red_f
                            , gdouble  *green_f
                            , gdouble  *blue_f
                            , gdouble  *alpha_f
                            , gdouble *opacity       /* output opacity 0.0 upto 1.0 */
                            , gdouble *scale_x       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                            , gdouble *scale_y       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                            , gdouble *move_x        /* output -1.0 upto 1.0 where 0.0 is centered */
                            , gdouble *move_y        /* output -1.0 upto 1.0 where 0.0 is centered */
                            , GapStoryRenderFrameRangeElem **frn_elem_ptr  /* OUT pointer to the relevant framerange element */
                           );
static void   p_calculate_frames_to_handle(GapStoryRenderFrameRangeElem *frn_elem);

static GapStoryRenderFrameRangeElem *  p_new_framerange_element(
                           GapStoryRenderFrameType  frn_type
                          ,gint32 track
                          ,const char *basename       /* basename or full imagename  for frn_type GAP_FRN_IMAGE */
                          ,const char *ext            /* NULL for frn_type GAP_FRN_IMAGE */
                          ,gint32  frame_from   /* IN: range start */
                          ,gint32  frame_to     /* IN: range end */
                          ,const char *storyboard_file  /* IN: NULL if no storyboard file is used */
                          ,const char *preferred_decoder  /* IN: NULL if no preferred_decoder is specified */
                          ,const char *filtermacro_file  /* IN: NULL, or name of the macro file */
                          ,GapStoryRenderFrameRangeElem *frn_list /* NULL or list of already known ranges */
                          ,GapStoryRenderErrors *sterr          /* element to store Error/Warning report */
                          ,gint32 seltrack      /* IN: select videotrack number 1 upto 99 for GAP_FRN_MOVIE */
                          ,gint32 exact_seek    /* IN: 0 fast seek, 1 exact seek (only for GVA Videoreads) */
                          ,gdouble delace    /* IN: 0.0 no deinterlace, 1.0-1.99 odd 2.0-2.99 even rows (only for GVA Videoreads) */
                          ,gdouble step_density    /* IN:  1==normal stepsize 1:1   0.5 == each frame twice, 2.0 only every 2nd frame */
                          ,gint32 flip_request            /* 0 NONE, 1 flip horizontal, 2 flip vertical, 3 rotate 180degree */
                          ,const char   *mask_name        /* reference to layer mask definition */
                          ,gdouble mask_stepsize          /* stepsize for the layer mask */
                          ,GapStoryMaskAnchormode mask_anchor  /* how to apply the layer mask */
                          ,gboolean mask_disable
                          );
static void       p_add_frn_list(GapStoryRenderVidHandle *vidhand, GapStoryRenderFrameRangeElem *frn_elem);
static void       p_step_all_vtrack_attributes(gint32 track, gint32 frames_to_handle
                       ,GapStoryRenderVTrackArray *vtarr
                      );
static void       p_set_vtrack_attributes(GapStoryRenderFrameRangeElem *frn_elem
                       ,GapStoryRenderVTrackArray *vtarr
                      );


static void       p_vidclip_add_as_is(GapStoryRenderFrameRangeElem *frn_elem
                      ,GapStoryRenderVidHandle *vidhand
                      ,GapStoryRenderVTrackArray *vtarr
                      );
static void       p_vidclip_shadow_add_silence(gint32 shadow_track
                      ,gint32 fill_shadow_frames
                      ,GapStoryRenderVidHandle *vidhand
                      ,GapStoryRenderVTrackArray *vtarr
                      ,const char *storyboard_file
                      );
static void       p_recalculate_range_part(GapStoryRenderFrameRangeElem *frn_elem
                      , gint32 lost_frames
                      , gint32 rest_frames
                      );
static void       p_copy_vattr_values(gint32 src_track
                      , gint32 dst_track
                      , GapStoryRenderVTrackArray *vtarr
                      );
static void       p_vidclip_split_and_add_frn_list(GapStoryRenderFrameRangeElem *frn_elem,
                      GapStoryRenderVidHandle *vidhand,
                      GapStoryRenderVTrackArray *vtarr,
                      const char *storyboard_file
                      );
static void       p_vidclip_add(GapStoryRenderFrameRangeElem *frn_elem
                      ,GapStoryRenderVidHandle *vidhand
                      ,GapStoryRenderVTrackArray *vtarr
                      ,const char *storyboard_file
                      ,gboolean first_of_group                      
                      );

static void       p_storyboard_analyze(GapStoryBoard *stb
                      , GapStoryRenderVTrackArray *vtarr
                      , GapStoryRenderVidHandle *vidhand
                      );
static GapStoryRenderFrameRangeElem *  p_framerange_list_from_storyboard(
                           const char *storyboard_file
                          ,gint32 *frame_count
                          ,GapStoryRenderVidHandle *vidhand
                          ,GapStoryBoard *stb_mem_ptr
                          );
static void       p_free_framerange_list(GapStoryRenderFrameRangeElem * frn_list);

static void       p_open_mask_vidhand(GapStoryElem *stb_elem
                          , GapStoryRenderMaskDefElem *maskdef_elem);
static void       p_copy_mask_definitions_to_vidhand(GapStoryBoard *stb_ptr
                          , GapStoryRenderVidHandle *vidhand);
static void       p_free_mask_definitions(GapStoryRenderVidHandle *vidhand);
static GapStoryRenderMaskDefElem * p_find_maskdef_by_name(GapStoryRenderVidHandle *vidhand, const char *mask_name);
static gint32     p_mask_fetcher(GapStoryRenderVidHandle *vidhand
                    , const char *mask_name
                    , gint32 master_frame_nr
                    , gint32 mask_width
                    , gint32 mask_height
                    , gint32 *layer_id               /* OUT: Id of the only layer in the composite image */
                    , gboolean *was_last_maskframe   /* OUT: true if this was the last maskframe */
                    );
static void       p_fetch_and_add_layermask(GapStoryRenderVidHandle *vidhand
                    , GapStoryRenderFrameRangeElem *frn_elem
                    , gint32 local_stepcount
                    , gint32 image_id
                    , gint32 layer_id
                    );

static GapStoryRenderVidHandle * p_open_video_handle_private(    gboolean ignore_audio
                      , gboolean ignore_video
		      , gboolean create_audio_tmp_files
                      , gdouble  *progress_ptr
                      , char *status_msg
                      , gint32 status_msg_len
                      , const char *storyboard_file
                      , const char *basename
                      , const char *ext
                      , gint32  frame_from
                      , gint32  frame_to
                      , gint32 *frame_count   /* output total frame_count , or 0 on failure */
                      , gboolean do_gimp_progress
		      , GapLibTypeInputRange input_mode
		      , const char *imagename
                      , const char *preferred_decoder
                      , gint32 seltrack
                      , gint32 exact_seek
                      , gdouble delace
                      , gboolean compensate_framerange
                      , GapStoryBoard *stb_mem_ptr
                      );
static gint32     p_exec_filtermacro(gint32 image_id, gint32 layer_id, const char *filtermacro_file);
static gint32     p_transform_and_add_layer( gint32 comp_image_id
                         , gint32 tmp_image_id
                         , gint32 layer_id
                         , gboolean keep_proportions
                         , gboolean fit_width
                         , gboolean fit_height
                         , gdouble opacity    /* 0.0 upto 1.0 */
                         , gdouble scale_x    /* 0.0 upto 10.0 where 1.0 = 1:1 */
                         , gdouble scale_y    /* 0.0 upto 10.0 where 1.0 = 1:1 */
                         , gdouble move_x     /* -1.0 upto +1.0 where 0 = no move, -1 is left outside */
                         , gdouble move_y     /* -1.0 upto +1.0 where 0 = no move, -1 is top outside */
                         , char *filtermacro_file
                         , gint32 flip_request
                         , GapStoryRenderFrameRangeElem *frn_elem
                         , GapStoryRenderVidHandle *vidhand
                         , gint32 local_stepcount
                         );
static gint32     p_create_unicolor_image(gint32 *layer_id, gint32 width , gint32 height
                       , gdouble r_f, gdouble g_f, gdouble b_f, gdouble a_f);
static gint32     p_prepare_RGB_image(gint32 image_id);
static t_GVA_Handle * p_try_to_steal_gvahand(GapStoryRenderVidHandle *vidhand
                      , gint32 master_frame_nr
                      , char *basename             /* the videofile name */
                      , gint32 exact_seek
                      );


/* ----------------------------------------------------
 * gap_story_render_debug_print_maskdef_elem
 * ----------------------------------------------------
 * print all List elements for the given track
 * (negative track number will print all elements)
 */
void
gap_story_render_debug_print_maskdef_elem(GapStoryRenderMaskDefElem *maskdef_elem, gint l_idx)
{
  if(maskdef_elem)
  {
      printf("\n  ===== maskdef_elem start ============ \n" );

      printf("  [%d] record_type       : %d\n", (int)l_idx, (int)maskdef_elem->record_type );
      printf("  [%d] mask_name         : ", (int)l_idx); if(maskdef_elem->mask_name) { printf("%s\n", maskdef_elem->mask_name );} else { printf ("(null)\n"); }
      printf("  [%d] mask_vidhand      : %d\n", (int)l_idx, (int)maskdef_elem->mask_vidhand );
      printf("  [%d] frame_count       : %d\n", (int)l_idx, (int)maskdef_elem->frame_count );
      printf("  [%d] flip_request      : %d\n", (int)l_idx, (int)maskdef_elem->flip_request );
      
      if(maskdef_elem->mask_vidhand)
      {
         printf("Storyboard list for this maskdef_elem:\n" );
         gap_story_render_debug_print_framerange_list(maskdef_elem->mask_vidhand->frn_list, -1);
      }

      printf("\n  ===== maskdef_elem end  ============ \n" );
      
  }
}  /* end gap_story_render_debug_print_maskdef_elem */

/* ----------------------------------------------------
 * p_frn_record_type_to_string
 * ----------------------------------------------------
 */
static const char *
p_frn_record_type_to_string(GapStoryRenderFrameType frn_type)
{
  switch(frn_type)
  {
    case GAP_FRN_SILENCE:     return("GAP_FRN_SILENCE"); break;
    case GAP_FRN_COLOR:       return("GAP_FRN_COLOR"); break;
    case GAP_FRN_IMAGE:       return("GAP_FRN_IMAGE"); break;
    case GAP_FRN_ANIMIMAGE:   return("GAP_FRN_ANIMIMAGE"); break;
    case GAP_FRN_FRAMES:      return("GAP_FRN_FRAMES"); break;
    case GAP_FRN_MOVIE:       return("GAP_FRN_MOVIE"); break;
  }
  return("** UNDEFINED RECORD TYPE **");
}  /* end p_frn_record_type_to_string */

/* ----------------------------------------------------
 * gap_story_render_debug_print_frame_elem
 * ----------------------------------------------------
 * print all List elements for the given track
 * (negative track number will print all elements)
 */
void
gap_story_render_debug_print_frame_elem(GapStoryRenderFrameRangeElem *frn_elem, gint l_idx)
{
  static const char *normal_track = " (normal)";
  static const char *shadow_track = " (shadow)";
  
  if(frn_elem)
  {
      const char *track_type;
      
      track_type = normal_track;
      if((frn_elem->track & 1) == 0)
      {
        track_type = shadow_track;
      }

      printf("\n  [%d] frn_type          : %d   %s\n", (int)l_idx, (int)frn_elem->frn_type
                                                ,p_frn_record_type_to_string(frn_elem->frn_type));
      printf("  [%d] itrack (internal) : %d  %s\n", (int)l_idx, (int)frn_elem->track, track_type );
      printf("  [%d] track (file)      : %d\n", (int)l_idx, (int)(1+(frn_elem->track / 2)) );
      printf("  [%d] basename          : ", (int)l_idx); if(frn_elem->basename) { printf("%s\n", frn_elem->basename );} else { printf ("(null)\n"); }
      printf("  [%d] ext               : ", (int)l_idx); if(frn_elem->ext) { printf("%s\n", frn_elem->ext );} else { printf ("(null)\n"); }
      printf("  [%d] gvahand           : %d\n", (int)l_idx, (int)frn_elem->gvahand );
      printf("  [%d] seltrack          : %d\n", (int)l_idx, (int)frn_elem->seltrack );
      printf("  [%d] exact_seek        : %d\n", (int)l_idx, (int)frn_elem->exact_seek );
      printf("  [%d] delace            : %.2f\n", (int)l_idx, (float)frn_elem->delace );
      printf("  [%d] filtermacro_file  : ", (int)l_idx); if(frn_elem->filtermacro_file) { printf("%s\n", frn_elem->filtermacro_file );} else { printf ("(null)\n"); }

      printf("  [%d] frame_from        : %.4f\n", (int)l_idx, (float)frn_elem->frame_from );
      printf("  [%d] frame_to          : %.4f\n", (int)l_idx, (float)frn_elem->frame_to );
      printf("  [%d] frames_to_handle  : %d\n", (int)l_idx, (int)frn_elem->frames_to_handle);
      printf("  [%d] delta             : %d\n", (int)l_idx, (int)frn_elem->delta );
      printf("  [%d] step_density      : %.4f\n", (int)l_idx, (float)frn_elem->step_density );

      if(frn_elem->keep_proportions)
      {printf("  [%d] keep_proportions  : TRUE\n", (int)l_idx );}
      else
      {printf("  [%d] keep_proportions  : FALSE\n", (int)l_idx );}

      if(frn_elem->fit_width)
      {printf("  [%d] fit_width         : TRUE\n", (int)l_idx );}
      else
      {printf("  [%d] fit_width         : FALSE\n", (int)l_idx );}

      if(frn_elem->fit_height)
      {printf("  [%d] fit_height        : TRUE\n", (int)l_idx );}
      else
      {printf("  [%d] fit_height        : FALSE\n", (int)l_idx );}


      printf("  [%d] flip_request       : %d\n", (int)l_idx, (int)frn_elem->flip_request );
      if(frn_elem->mask_name)
      {
        printf("  [%d] mask_name         : %s\n", (int)l_idx,  frn_elem->mask_name);
        printf("  [%d] mask_anchor       : %d\n", (int)l_idx, (int)frn_elem->mask_anchor );
        printf("  [%d] mask_stepsize     : %.4f\n", (int)l_idx, (float)frn_elem->mask_stepsize );
        printf("  [%d] mask_framecount   : %.4f\n", (int)l_idx, (float)frn_elem->mask_framecount );
      }
      else
      {
        printf("  [%d] mask_name         : (null)\n", (int)l_idx );
      }
      


      printf("  [%d] wait_untiltime_sec : %f\n", (int)l_idx, (float)frn_elem->wait_untiltime_sec );
      printf("  [%d] wait_untilframes   : %d\n", (int)l_idx, (int)frn_elem->wait_untilframes );


      printf("  [%d] opacity_from      : %f\n", (int)l_idx, (float)frn_elem->opacity_from );
      printf("  [%d] opacity_to        : %f\n", (int)l_idx, (float)frn_elem->opacity_to );
      printf("  [%d] opacity_dur       : %d\n", (int)l_idx, (int)frn_elem->opacity_dur );

      printf("  [%d] scale_x_from      : %f\n", (int)l_idx, (float)frn_elem->scale_x_from );
      printf("  [%d] scale_x_to        : %f\n", (int)l_idx, (float)frn_elem->scale_x_to );
      printf("  [%d] scale_x_dur       : %d\n", (int)l_idx, frn_elem->scale_x_dur );

      printf("  [%d] scale_y_from      : %f\n", (int)l_idx, (float)frn_elem->scale_y_from );
      printf("  [%d] scale_y_to        : %f\n", (int)l_idx, (float)frn_elem->scale_y_to );
      printf("  [%d] scale_y_dur       : %d\n", (int)l_idx, (int)frn_elem->scale_y_dur );

      printf("  [%d] move_x_from       : %f\n", (int)l_idx, (float)frn_elem->move_x_from );
      printf("  [%d] move_x_to         : %f\n", (int)l_idx, (float)frn_elem->move_x_to );
      printf("  [%d] move_x_dur        : %d\n", (int)l_idx, (int)frn_elem->move_x_dur );

      printf("  [%d] move_y_from       : %f\n", (int)l_idx, (float)frn_elem->move_y_from );
      printf("  [%d] move_y_to         : %f\n", (int)l_idx, (float)frn_elem->move_y_to );
      printf("  [%d] move_y_dur        : %d\n", (int)l_idx, (int)frn_elem->move_y_dur );
  }
}  /* end gap_story_render_debug_print_frame_elem */

/* ----------------------------------------------------
 * gap_story_render_debug_print_framerange_list
 * ----------------------------------------------------
 * print all List elements for the given track
 * (negative track number will print all elements)
 */
void
gap_story_render_debug_print_framerange_list(GapStoryRenderFrameRangeElem *frn_list
                             , gint32 track                    /* -1 show all tracks */
                             )
{
  GapStoryRenderFrameRangeElem *frn_elem;
  gint                 l_idx;

  printf("\ngap_story_render_debug_print_framerange_list: START\n");

  l_idx = 0;
  for(frn_elem = frn_list; frn_elem != NULL; frn_elem = (GapStoryRenderFrameRangeElem *)frn_elem->next)
  {
    if((frn_elem->track == track) || (track < 0))
    {
      gap_story_render_debug_print_frame_elem(frn_elem, l_idx);
    }
    l_idx++;
  }

  printf("gap_story_render_debug_print_framerange_list: END\n");

}  /* end gap_story_render_debug_print_framerange_list */


/* ----------------------------------------------------
 * gap_story_render_debug_print_audiorange_list
 * ----------------------------------------------------
 * print all List elements for the given track
 * (negative track number will print all elements)
 */
void
gap_story_render_debug_print_audiorange_list(GapStoryRenderAudioRangeElem *aud_list
                             , gint32 track                    /* -1 show all tracks */
                             )
{
  GapStoryRenderAudioRangeElem *aud_elem;
  gint                 l_idx;

  printf("\ngap_story_render_debug_print_audiorange_list: START\n");

  l_idx = 0;
  for(aud_elem = aud_list; aud_elem != NULL; aud_elem = (GapStoryRenderAudioRangeElem *)aud_elem->next)
  {
    if((aud_elem->track == track) || (track < 0))
    {
      printf("\n  [%d] aud_type         : %d\n", (int)l_idx, (int)aud_elem->aud_type );
      printf("  [%d] track             : %d\n", (int)l_idx, (int)aud_elem->track );
      printf("  [%d] audiofile         : ", (int)l_idx); if(aud_elem->audiofile) { printf("%s\n", aud_elem->audiofile );} else { printf ("(null)\n"); }
      printf("  [%d] tmp_audiofile     : ", (int)l_idx); if(aud_elem->tmp_audiofile) { printf("%s\n", aud_elem->tmp_audiofile );} else { printf ("(null)\n"); }
      printf("  [%d] gvahand           : %d\n", (int)l_idx, (int)aud_elem->gvahand );
      printf("  [%d] seltrack          : %d\n", (int)l_idx, (int)aud_elem->seltrack );

      printf("  [%d] samplerate        : %d\n", (int)l_idx, (int)aud_elem->samplerate );
      printf("  [%d] channels          : %d\n", (int)l_idx, (int)aud_elem->channels );
      printf("  [%d] bytes_per_sample  : %d\n", (int)l_idx, (int)aud_elem->bytes_per_sample );
      printf("  [%d] samples           : %d\n", (int)l_idx, (int)aud_elem->samples );


      printf("  [%d] audio_id          : %d\n", (int)l_idx, (int)aud_elem->audio_id);
      printf("  [%d] aud_data          : %d\n", (int)l_idx, (int)aud_elem->aud_data);
      printf("  [%d] aud_bytelength    : %d\n", (int)l_idx, (int)aud_elem->aud_bytelength);

      printf("  [%d] range_samples     : %d\n", (int)l_idx, (int)aud_elem->range_samples );
      printf("  [%d] fade_in_samples   : %d\n", (int)l_idx, (int)aud_elem->fade_in_samples );
      printf("  [%d] fade_out_samples  : %d\n", (int)l_idx, (int)aud_elem->fade_out_samples );
      printf("  [%d] offset_rangestart : %d\n", (int)l_idx, (int)aud_elem->byteoffset_rangestart );
      printf("  [%d] byteoffset_data   : %d\n", (int)l_idx, (int)aud_elem->byteoffset_data );


      printf("  [%d] wait_untiltime_sec: %f\n", (int)l_idx, (float)aud_elem->wait_untiltime_sec );
      printf("  [%d] wait_until_samples: %d\n", (int)l_idx, (int)aud_elem->wait_until_samples );

      printf("  [%d] max_playtime_sec  : %f\n", (int)l_idx, (float)aud_elem->max_playtime_sec );
      printf("  [%d] range_playtime_sec: %f\n", (int)l_idx, (float)aud_elem->range_playtime_sec );
      printf("  [%d] play_from_sec     : %f\n", (int)l_idx, (float)aud_elem->play_from_sec );
      printf("  [%d] play_to_sec       : %f\n", (int)l_idx, (float)aud_elem->play_to_sec );
      printf("  [%d] volume_start      : %f\n", (int)l_idx, (float)aud_elem->volume_start );
      printf("  [%d] volume            : %f\n", (int)l_idx, (float)aud_elem->volume );
      printf("  [%d] volume_end        : %f\n", (int)l_idx, (float)aud_elem->volume_end );
      printf("  [%d] fade_in_sec       : %f\n", (int)l_idx, (float)aud_elem->fade_in_sec );
      printf("  [%d] fade_out_sec      : %f\n", (int)l_idx, (float)aud_elem->fade_out_sec );
    }
    l_idx++;
  }

  printf("gap_story_render_debug_print_audiorange_list: END\n");

}  /* end gap_story_render_debug_print_audiorange_list */



/* ----------------------------------------------------
 * p_frame_backup_save
 * ----------------------------------------------------
 * set layer to unique color
 */
static void
p_frame_backup_save(  char *key
              , gint32 image_id
              , gint32 layer_id
              , gint32  master_frame_nr
              , gboolean multilayer
             )
{
  gint32  l_len;
  char *l_framename;
  char *l_basename;

  l_len = gimp_get_data_size(key);
  if(l_len <= 0)
  {
    return;
  }

  l_basename  = g_malloc0(l_len);
  gimp_get_data(key, l_basename);
  if(*l_basename != '\0')
  {
    if(multilayer)
    {
      l_framename = gap_lib_alloc_fname(l_basename, master_frame_nr, ".xcf");
    }
    else
    {
      l_framename = gap_lib_alloc_fname(l_basename, master_frame_nr, ".jpg");
    }

    if(gap_debug) printf("Debug: Saving frame to  file: %s\n", l_framename);

    gimp_file_save(GIMP_RUN_WITH_LAST_VALS, image_id, layer_id, l_framename, l_framename);
    g_free(l_framename);
  }
  g_free(l_basename);
}  /* end p_frame_backup_save */


/* ----------------------------------------------------
 * p_debug_dup_image
 * ----------------------------------------------------
 * Duplicate image, and open a display for the duplicate
 * (Procedure is used for debug only
 */
static void
p_debug_dup_image(gint32 image_id)
{
  gint32 l_dup_image_id;

  l_dup_image_id = gimp_image_duplicate(image_id);
  gimp_display_new(l_dup_image_id);
}  /* end p_debug_dup_image */


/* ----------------------------------------------------
 * p_encoding_monitor
 * ----------------------------------------------------
 * monitor the image before passed to the encoder.
 * - at 1.st call open global_monitor_image_id
 *       and add a display.
 * - on all further calls copy the composite layer
 *      to the global_monitor_image_id
 */
static void
p_encoding_monitor(  char *key
              , gint32 image_id
              , gint32 layer_id
              , gint32  master_frame_nr
             )
{
  gint32  l_len;
  char *l_true_or_false;

  l_len = gimp_get_data_size(key);
  if(l_len <= 0)
  {
    return;
  }

  l_true_or_false  = g_malloc0(l_len);
  gimp_get_data(key, l_true_or_false);
  if(*l_true_or_false == 'T')
  {
     char *l_imagename;

     printf("Monitoring image_id: %d, layer_id:%d  master_frame:%d\n", (int)image_id, (int)layer_id ,(int)master_frame_nr );

     l_imagename = g_strdup_printf(_("encoding_video_frame_%06d"), (int)master_frame_nr);
     if(global_monitor_image_id < 0)
     {
       global_monitor_image_id = gimp_image_duplicate(image_id);
       global_monitor_display_id = gimp_display_new(global_monitor_image_id);
       gimp_image_set_filename(global_monitor_image_id, l_imagename);
     }
     else
     {
       gint          l_nlayers;
       gint32       *l_layers_list;
       gint32        l_fsel_layer_id;

       l_layers_list = gimp_image_get_layers(global_monitor_image_id, &l_nlayers);
       if(l_layers_list != NULL)
       {
         gimp_selection_none(image_id);  /* if there is no selection, copy the complete layer */
         gimp_selection_none(global_monitor_image_id);  /* if there is no selection, copy the complete layer */
         gimp_edit_copy(layer_id);
         l_fsel_layer_id = gimp_edit_paste(l_layers_list[0], FALSE);  /* FALSE paste clear selection */
         gimp_floating_sel_anchor(l_fsel_layer_id);
         g_free (l_layers_list);
         gimp_image_set_filename(global_monitor_image_id, l_imagename);
         gimp_displays_flush();
       }
       else
       {
          printf("no more MONITORING, (user has closed monitor image)\n");
       }
     }
     g_free(l_imagename);
  }
  g_free(l_true_or_false);
}  /* end p_encoding_monitor */



/* --------------------------------
 * p_init_stb_error
 * --------------------------------
 */
static void
p_init_stb_error(GapStoryRenderErrors *sterr)
{
  if(sterr->errtext)   { g_free(sterr->errtext); }
  if(sterr->errline)   { g_free(sterr->errline); }
  if(sterr->warntext)  { g_free(sterr->warntext); }
  if(sterr->warnline)  { g_free(sterr->warnline); }

  sterr->errtext     = NULL;
  sterr->errline     = NULL;
  sterr->warntext    = NULL;
  sterr->warnline    = NULL;
  sterr->currline    = NULL;
  sterr->errline_nr  = 0;
  sterr->warnline_nr = 0;
  sterr->curr_nr     = 0;
}  /* end p_init_stb_error */

/* --------------------------------
 * p_new_stb_error
 * --------------------------------
 */
static GapStoryRenderErrors *
p_new_stb_error(void)
{
  GapStoryRenderErrors *sterr;

  sterr = g_malloc0(sizeof(GapStoryRenderErrors));
  p_init_stb_error(sterr);
  return(sterr);
}  /* end p_new_stb_error */

/* --------------------------------
 * p_free_stb_error
 * --------------------------------
 */
static void
p_free_stb_error(GapStoryRenderErrors *sterr)
{
  p_init_stb_error(sterr);
  g_free(sterr);
}  /* end p_free_stb_error */

/* --------------------------------
 * p_set_stb_error
 * --------------------------------
 */
static void
p_set_stb_error(GapStoryRenderErrors *sterr, char *errtext)
{
  printf("** error: %s\n   [at line:%d] %s\n"
        , errtext
        , (int)sterr->curr_nr
        , sterr->currline
        );
  if(sterr->errtext == NULL)
  {
     sterr->errtext     = g_strdup(errtext);
     sterr->errline_nr  = sterr->curr_nr;
     sterr->errline     = g_strdup(sterr->currline);
  }
}  /* end p_set_stb_error */

/* --------------------------------
 * gap_story_render_set_stb_error
 * --------------------------------
 */
void
gap_story_render_set_stb_error(GapStoryRenderErrors *sterr, char *errtext)
{
  p_set_stb_error(sterr, errtext);
}  /* end gap_story_render_set_stb_error */

/* --------------------------------
 * gap_story_render_set_stb_warning
 * --------------------------------
 */
void
gap_story_render_set_stb_warning(GapStoryRenderErrors *sterr, char *warntext)
{
  printf("** warning: %s\n   [at line:%d] %s\n"
        , warntext
        , (int)sterr->curr_nr
        , sterr->currline
        );
  if(sterr->warntext == NULL)
  {
     sterr->warntext     = g_strdup(warntext);
     sterr->warnline_nr  = sterr->curr_nr;
     sterr->warnline     = g_strdup(sterr->currline);
  }
}  /* end gap_story_render_set_stb_warning */


/* ----------------------------------------------------
 * p_drop_image_cache_elem1
 * ----------------------------------------------------
 */
static void
p_drop_image_cache_elem1(GapStoryRenderImageCache *imcache)
{
  GapStoryRenderImageCacheElem  *ic_ptr;

  if(imcache)
  {
    ic_ptr = imcache->ic_list;
    if(ic_ptr)
    {
      if(gap_debug) printf("p_drop_image_cache_elem1 delete:%s (image_id:%d)\n", ic_ptr->filename, (int)ic_ptr->image_id);
      gap_image_delete_immediate(ic_ptr->image_id);
      g_free(ic_ptr->filename);
      imcache->ic_list = (GapStoryRenderImageCacheElem  *)ic_ptr->next;
      g_free(ic_ptr);
    }
  }
}  /* end p_drop_image_cache_elem1 */


/* ----------------------------------------------------
 * gap_story_render_drop_image_cache
 * ----------------------------------------------------
 */
void
gap_story_render_drop_image_cache(void)
{
  GapStoryRenderImageCache *imcache;

  if(gap_debug)  printf("gap_story_render_drop_image_cache START\n");
  imcache = global_imcache;
  if(imcache)
  {
    while(imcache->ic_list)
    {
      p_drop_image_cache_elem1(imcache);
    }
  }
  if(gap_debug) printf("gap_story_render_drop_image_cache END\n");

}  /* end gap_story_render_drop_image_cache */


/* ----------------------------------------------------
 * p_load_cache_image
 * ----------------------------------------------------
 */
static gint32
p_load_cache_image( char* filename)
{
  gint32 l_idx;
  gint32 l_image_id;
  GapStoryRenderImageCacheElem  *ic_ptr;
  GapStoryRenderImageCacheElem  *ic_last;
  GapStoryRenderImageCacheElem  *ic_new;
  GapStoryRenderImageCache  *imcache;

  if(filename == NULL)
  {
    printf("p_load_cache_image: ** ERROR cant load filename == NULL!\n");
    return -1;
  }

  if(global_imcache == NULL)
  {
    /* init the global_image cache */
    global_imcache = g_malloc0(sizeof(GapStoryRenderImageCache));
    global_imcache->ic_list = NULL;
    global_imcache->max_img_cache = MAX_IMG_CACHE_ELEMENTS;
  }

  imcache = global_imcache;
  ic_last = imcache->ic_list;

  l_idx = 0;
  for(ic_ptr = imcache->ic_list; ic_ptr != NULL; ic_ptr = (GapStoryRenderImageCacheElem *)ic_ptr->next)
  {
    l_idx++;
    if(strcmp(filename, ic_ptr->filename) == 0)
    {
      /* image found in cache, can skip load */
      return(ic_ptr->image_id);
    }
    ic_last = ic_ptr;
  }

  l_image_id = gap_lib_load_image(filename);
  if(l_image_id >= 0)
  {
    ic_new = g_malloc0(sizeof(GapStoryRenderImageCacheElem));
    ic_new->filename = g_strdup(filename);
    ic_new->image_id = l_image_id;

    if(imcache->ic_list == NULL)
    {
      imcache->ic_list = ic_new;   /* 1.st elem starts the list */
    }
    else
    {
      ic_last->next = (GapStoryRenderImageCacheElem *)ic_new;  /* add new elem at end of the cache list */
    }

    if(l_idx > imcache->max_img_cache)
    {
      /* chache list has more elements than desired,
       * drop the 1.st (oldest) entry in the chache list
       */
      p_drop_image_cache_elem1(imcache);
    }
  }
  return(l_image_id);
}  /* end p_load_cache_image */




/* ----------------------------------------------------
 * p_find_min_max_vid_tracknumbers
 * ----------------------------------------------------
 * findout the lowest and highest track number used
 * in the framerange list
 */
static void
p_find_min_max_vid_tracknumbers(GapStoryRenderFrameRangeElem *frn_list
                             , gint32 *lowest_tracknr
                             , gint32 *highest_tracknr
                             )
{
  GapStoryRenderFrameRangeElem *frn_elem;

  *lowest_tracknr = GAP_STB_MAX_VID_INTERNAL_TRACKS;
  *highest_tracknr = -1;

  for(frn_elem = frn_list; frn_elem != NULL; frn_elem = (GapStoryRenderFrameRangeElem *)frn_elem->next)
  {
    if (frn_elem->track > *highest_tracknr)
    {
      *highest_tracknr = frn_elem->track;
    }
    if (frn_elem->track < *lowest_tracknr)
    {
      *lowest_tracknr = frn_elem->track;
    }

  }

  if(gap_debug) printf("p_find_min_max_vid_tracknumbers: min:%d max:%d\n", (int)*lowest_tracknr, (int)*highest_tracknr);

}  /* end p_find_min_max_vid_tracknumbers */


/* ---------------------------------------
 * p_step_attribute
 * ---------------------------------------
 * calculate remaining attribute value after N frames_handled
 * and change *from_val and *dur accordingly
 */
static void
p_step_attribute(gint32 frames_handled
                ,gdouble *from_val
                ,gdouble *to_val
                ,gint32  *dur
                )
{
  gint32 l_rest_steps;
  gdouble step_delta_val;

  l_rest_steps =  *dur  - frames_handled;
  if((l_rest_steps <= 0) || (*dur <= 0))
  {
    *from_val = *to_val;
    *dur = 0;
  }
  else
  {
    step_delta_val =  (*to_val - *from_val) / (gdouble)(*dur);

    *from_val = *to_val - (step_delta_val * l_rest_steps) ;
    *dur = l_rest_steps;
  }
}  /* end p_step_attribute */



/* --------------------------------
 * p_step_attribute_read
 * --------------------------------
 * return attribute value after N frame steps
 */
static gdouble
p_step_attribute_read(gint32 frame_step
                ,gdouble from_val
                ,gdouble to_val
                ,gint32  dur
                )
{
  gdouble l_from_val;
  gdouble l_to_val;
  gint32  l_dur;

  l_from_val    = from_val;
  l_to_val      = to_val;
  l_dur         = dur;

  p_step_attribute( frame_step
                  , &l_from_val
                  , &l_to_val
                  , &l_dur
                  );

  return(l_from_val);

}  /* end p_step_attribute */


/* ----------------------------------------------------
 * p_fetch_framename
 * ----------------------------------------------------
 * fetch framename for a given master_frame_nr in the given video track
 * within a storyboard framerange list.
 * (simple animations without a storyboard file
 *  are represented by a short storyboard framerange list that has
 *  just one element entry at track 1).
 *
 * output gduoble attribute values (opacity, scale, move) for the frame
 * at track and master_frame_nr position.
 *
 * return the name of the frame (that is to be displayed at position master_frame_nr).
 * return NULL if there is no frame at desired track and master_frame_nr
 */
static char *
p_fetch_framename(GapStoryRenderFrameRangeElem *frn_list
                 , gint32 master_frame_nr      /* starts at 1 */
                 , gint32 track
                 , GapStoryRenderFrameType *frn_type
                 , char **filtermacro_file
                 , gint32   *localframe_index  /* starts at 1, used for ANIMIMAGE and VIDEOFILES, -1 for all other types */
                 , gint32   *local_stepcount   /* nth frame within this clip, starts with 0 */
                 , gboolean *keep_proportions
                 , gboolean *fit_width
                 , gboolean *fit_height
                 , gdouble  *red_f
                 , gdouble  *green_f
                 , gdouble  *blue_f
                 , gdouble  *alpha_f
                 , gdouble *opacity       /* output opacity 0.0 upto 1.0 */
                 , gdouble *scale_x       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                 , gdouble *scale_y       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                 , gdouble *move_x        /* output -1.0 upto 1.0 where 0.0 is centered */
                 , gdouble *move_y        /* output -1.0 upto 1.0 where 0.0 is centered */
                 , GapStoryRenderFrameRangeElem **frn_elem_ptr  /* OUT pointer to the relevant framerange element */
                 )
{
  GapStoryRenderFrameRangeElem *frn_elem;
  char   *l_framename;
  gint32  l_frame_group_count;
  gint32  l_fnr;
  gint32  l_step;
  gint32  l_found_at_idx;
  gint32  l_frames_to_handle;

  l_frame_group_count = 0;
  l_framename = NULL;

  /* default attributes (used if storyboard does not define settings) */
  *opacity = 1.0;
  *scale_x = 1.0;
  *scale_y = 1.0;
  *move_x  = 0.0;
  *move_y  = 0.0;
  *localframe_index = -1;
  *local_stepcount = 0;
  *frn_type = GAP_FRN_SILENCE;
  *keep_proportions = FALSE;
  *fit_width        = TRUE;
  *fit_height       = TRUE;
  *red_f            = 0.0;
  *green_f          = 0.0;
  *blue_f           = 0.0;
  *alpha_f          = 1.0;
  *filtermacro_file = NULL;
  *frn_elem_ptr      = NULL;

  l_found_at_idx=0;
  for (frn_elem = frn_list; frn_elem != NULL; frn_elem = (GapStoryRenderFrameRangeElem *)frn_elem->next)
  {
    if(frn_elem->track == track)
    {
      l_frames_to_handle = frn_elem->frames_to_handle;
      if (frn_elem->wait_untiltime_sec > 0)
      {
        l_frames_to_handle += MAX(0, frn_elem->wait_untilframes - l_frame_group_count);
      }
      if (master_frame_nr <= l_frame_group_count + l_frames_to_handle)
      {
        gdouble fnr;

        /* calculate positive or negative offset from_frame to desired frame */
	fnr = (gdouble)(frn_elem->delta * (master_frame_nr - (l_frame_group_count +1 )))
	      * frn_elem->step_density;
        
        /* calculate framenumber local to the clip */
        l_fnr = (gint32)(frn_elem->frame_from + fnr);

        *local_stepcount = master_frame_nr - l_frame_group_count;
        *local_stepcount -= 1;


        if((frn_elem->frn_type == GAP_FRN_SILENCE)
        || (frn_elem->frn_type == GAP_FRN_COLOR))
        {
          l_framename = NULL;   /* there is no filename for video silence or unicolor */
        }
        if(frn_elem->frn_type == GAP_FRN_IMAGE)
        {
          l_framename = g_strdup(frn_elem->basename);   /* use 1:1 basename for single images */
        }
        if(frn_elem->frn_type == GAP_FRN_ANIMIMAGE )
        {
          l_framename = g_strdup(frn_elem->basename);   /* use 1:1 basename for ainimated single images */
          *localframe_index = l_fnr;                    /* local frame number is index in the layerstack */
        }
        if(frn_elem->frn_type == GAP_FRN_MOVIE )
        {
          /* video file frame numners start at 1 */
          l_framename = g_strdup(frn_elem->basename);   /* use 1:1 basename for videofiles */
          *localframe_index = l_fnr;                    /* local frame number is the wanted video frame number */
        }
        if(frn_elem->frn_type == GAP_FRN_FRAMES)
        {
          l_framename = gap_lib_alloc_fname(frn_elem->basename
                                   ,l_fnr
                                   ,frn_elem->ext
                                   );
        }
         /* return values for current fixed attribute settings
          */
         *frn_type         = frn_elem->frn_type;
         *keep_proportions = frn_elem->keep_proportions;
         *fit_width        = frn_elem->fit_width;
         *fit_height       = frn_elem->fit_height;
         *red_f            = frn_elem->red_f;
         *green_f          = frn_elem->green_f;
         *blue_f           = frn_elem->blue_f;
         *alpha_f          = frn_elem->alpha_f;
         *filtermacro_file = frn_elem->filtermacro_file;

         frn_elem->last_master_frame_access = master_frame_nr;

         *frn_elem_ptr     = frn_elem;  /* deliver pointer to the current frn_elem */


         /* calculate effect attributes for the current step
          * where l_step = 0 at the 1.st frame of the local range
          */
         l_step = (master_frame_nr - 1) - l_frame_group_count;



         *opacity = p_step_attribute_read(l_step
                                    , frn_elem->opacity_from
                                    , frn_elem->opacity_to
                                    , frn_elem->opacity_dur
                                    );
         *scale_x = p_step_attribute_read(l_step
                                    , frn_elem->scale_x_from
                                    , frn_elem->scale_x_to
                                    , frn_elem->scale_x_dur
                                    );
         *scale_y = p_step_attribute_read(l_step
                                    , frn_elem->scale_y_from
                                    , frn_elem->scale_y_to
                                    , frn_elem->scale_y_dur
                                    );
         *move_x  = p_step_attribute_read(l_step
                                    , frn_elem->move_x_from
                                    , frn_elem->move_x_to
                                    , frn_elem->move_x_dur
                                    );
         *move_y  = p_step_attribute_read(l_step
                                    , frn_elem->move_y_from
                                    , frn_elem->move_y_to
                                    , frn_elem->move_y_dur
                                    );
        break;
      }
      l_frame_group_count += l_frames_to_handle;
    }
    l_found_at_idx++;
  }

  if(gap_debug)
  {
   printf("p_fetch_framename: track:%d master_frame_nr:%d framename:%s: found_at_idx:%d opa:%f scale:%f %f move:%f %f layerstack_idx:%d\n"
       ,(int)track
       ,(int)master_frame_nr
       , l_framename
       ,(int)l_found_at_idx
       , (float)*opacity
       , (float)*scale_x
       , (float)*scale_y
       , (float)*move_x
       , (float)*move_y
       , (int)*localframe_index
       );
  }

  return l_framename;
}       /* end p_fetch_framename */



/* ---------------------------------
 * p_calculate_frames_to_handle
 * ---------------------------------
 */
static void
p_calculate_frames_to_handle(GapStoryRenderFrameRangeElem *frn_elem)
{
    gdouble fnr;

    if(frn_elem->step_density <= 0)
    {
      /* force legal value */
      frn_elem->step_density = 1.0;
    }
    
    fnr = (gdouble)(ABS(frn_elem->frame_from - frn_elem->frame_to) +1);
    fnr = fnr / frn_elem->step_density;
    frn_elem->frames_to_handle = MAX((gint32)(fnr + 0.5), 1);
}  /* end p_calculate_frames_to_handle */


/* ----------------------------------------------------
 * p_new_framerange_element
 * ----------------------------------------------------
 * allocate a new GapStoryRenderFrameRangeElem for storyboard processing
 * - read directory to check for first and last available frame Number
 *   for the given filename and extension.
 * - findout processing order (1 ascending, -1 descending)
 * - findout frames_to_handle in the given range.
 *
 * Single images are added with frn_type == GAP_FRN_IMAGE
 *  and frame_from = 1
 *  and frame_to   = N   (10 if image is to display for duration of 10 frames)
 *
 * return GapStoryRenderFrameRangeElem with allocated copies of basename and ext strings.
 */
static GapStoryRenderFrameRangeElem *
p_new_framerange_element(GapStoryRenderFrameType  frn_type
                      ,gint32 track
                      ,const char *basename           /* basename or full imagename  for frn_type GAP_FRN_IMAGE */
                      ,const char *ext                /* NULL for frn_type GAP_FRN_IMAGE and GAP_FRN_MOVIE */
                      ,gint32  frame_from             /* IN: range start */
                      ,gint32  frame_to               /* IN: range end */
                      ,const char *storyboard_file    /* IN: NULL if no storyboard file is used */
                      ,const char *preferred_decoder  /* IN: NULL if no preferred_decoder is specified */
                      ,const char *filtermacro_file   /* IN: NULL, or name of the macro file */
                      ,GapStoryRenderFrameRangeElem *frn_list /* NULL or list of already known ranges */
                      ,GapStoryRenderErrors *sterr           /* element to store Error/Warning report */
                      ,gint32 seltrack      /* IN: select videotrack number 1 upto 99 for GAP_FRN_MOVIE */
                      ,gint32 exact_seek    /* IN: 0 fast seek, 1 exact seek (only for GVA Videoreads) */
                      ,gdouble delace    /* IN: 0.0 no deinterlace, 1.0-1.99 odd 2.0-2.99 even rows (only for GVA Videoreads) */
                      ,gdouble step_density    /* IN:  1==normal stepsize 1:1   0.5 == each frame twice, 2.0 only every 2nd frame */
                      ,gint32 flip_request            /* 0 NONE, 1 flip horizontal, 2 flip vertical, 3 rotate 180degree */
                      ,const char   *mask_name        /* reference to layer mask definition */
                      ,gdouble mask_stepsize          /* stepsize for the layer mask */
                      ,GapStoryMaskAnchormode mask_anchor  /* how to apply the layer mask */
                      ,gboolean mask_disable
                      )
{
  GapStoryRenderFrameRangeElem *frn_elem;

  if(gap_debug)
  {
     printf("\np_new_framerange_element: START frn_type:%d\n", (int)frn_type);
     printf("  track:%d:\n", (int)track);
     printf("  frame_from:%d:\n", (int)frame_from);
     printf("  frame_to:%d:\n", (int)frame_to);
     printf("  step_density:%f:\n", (float)step_density);
     if(basename)          printf("  basename:%s:\n", basename);
     if(ext)               printf("  ext:%s:\n", ext);
     if(storyboard_file)   printf("  storyboard_file:%s:\n", storyboard_file);
     if(preferred_decoder) printf("  preferred_decoder:%s:\n", preferred_decoder);
  }


  frn_elem = g_malloc0(sizeof(GapStoryRenderFrameRangeElem));
  frn_elem->frn_type         = frn_type;
  frn_elem->track            = track;
  frn_elem->frame_from       = frame_from;
  frn_elem->frame_to         = frame_to;
  frn_elem->frames_to_handle = 0;
  frn_elem->delta            = 1;
  frn_elem->step_density     = step_density;
  frn_elem->last_master_frame_access = -1;   /* -1 indicate that there was no access */

  frn_elem->flip_request  = flip_request;
  frn_elem->mask_framecount = 0;
  frn_elem->mask_stepsize = mask_stepsize;
  frn_elem->mask_anchor   = mask_anchor;
  
  /* disabled masks are ignored for storyboard processing
   * by using a mask_name == NULL
   */
  frn_elem->mask_name     = NULL;
  if(!mask_disable)
  {
    if(mask_name)
    {
      frn_elem->mask_name = g_strdup(mask_name);
    }
  }

  /* default attributes (used if storyboard does not define settings) */
  frn_elem->red_f              = 0.0;
  frn_elem->green_f            = 0.0;
  frn_elem->blue_f             = 0.0;
  frn_elem->alpha_f            = 1.0;
  frn_elem->keep_proportions   = FALSE;
  frn_elem->fit_width          = TRUE;
  frn_elem->fit_height         = TRUE;
  frn_elem->wait_untiltime_sec = 0.0;
  frn_elem->wait_untilframes   = 0;
  frn_elem->opacity_from       = 1.0;
  frn_elem->opacity_to         = 1.0;
  frn_elem->opacity_dur        = 0;
  frn_elem->scale_x_from       = 1.0;
  frn_elem->scale_x_to         = 1.0;
  frn_elem->scale_x_dur        = 0;
  frn_elem->scale_y_from       = 1.0;
  frn_elem->scale_y_to         = 1.0;
  frn_elem->scale_y_dur        = 0;
  frn_elem->move_x_from        = 0.0;
  frn_elem->move_x_to          = 0.0;
  frn_elem->move_x_dur         = 0;
  frn_elem->move_y_from        = 0.0;
  frn_elem->move_y_to          = 0.0;
  frn_elem->move_y_dur         = 0;
  frn_elem->filtermacro_file   = NULL;
  frn_elem->gvahand            = NULL;
  frn_elem->seltrack           = seltrack;
  frn_elem->exact_seek         = exact_seek;
  frn_elem->delace             = delace;
  frn_elem->next               = NULL;


  if(ext)
  {
    if(*ext == '.')
    {
      frn_elem->ext              = g_strdup(ext);
    }
    else
    {
      frn_elem->ext              = g_strdup_printf(".%s", ext);
    }
  }

  /* check basename for absolute pathname */
  if(basename)
  {
     frn_elem->basename = gap_file_make_abspath_filename(basename, storyboard_file);
  } /* end check for absolute pathname */

  /* check filtermacro_file for absolute pathname */
  frn_elem->filtermacro_file      = NULL;
  if(filtermacro_file)
  {
    if(*filtermacro_file != '\0')
    {
      frn_elem->filtermacro_file = gap_file_make_abspath_filename(filtermacro_file, storyboard_file);

      if(!g_file_test(frn_elem->filtermacro_file, G_FILE_TEST_EXISTS))
      {
         char *l_errtxt;

         l_errtxt = g_strdup_printf("filtermacro_file not found:  %s", frn_elem->filtermacro_file);
         p_set_stb_error(sterr, l_errtxt);
         g_free(l_errtxt);
         g_free(frn_elem->filtermacro_file);
         frn_elem->filtermacro_file = NULL;
      }
    }
  }


  /* check processing order delta */
  if (frn_elem->frame_from > frn_elem->frame_to)
  {
    frn_elem->delta            = -1;   /* -1 is inverse (descending) order */
  }
  else
  {
    frn_elem->delta            = 1;    /* +1 is normal (ascending) order */
  }
  
  
  /* calculate frames_to_handle respecting step_density */ 
  p_calculate_frames_to_handle(frn_elem);

  if(gap_debug)
  {
    if(frn_elem->basename) printf("\np_new_framerange_element: frn_elem->basename:%s:\n", frn_elem->basename);
    if(frn_elem->ext)      printf("p_new_framerange_element: frn_elem->ext:%s:\n",frn_elem->ext);
    printf("p_new_framerange_element: frn_elem->frame_from:%d:\n", (int)frn_elem->frame_from);
    printf("p_new_framerange_element: frn_elem->frame_to:%d:\n", (int)frn_elem->frame_to);
    printf("p_new_framerange_element: frn_elem->frames_to_handle:%d:\n", (int)frn_elem->frames_to_handle);
    printf("\np_new_framerange_element: END\n");
  }


  return(frn_elem);
}       /* end p_new_framerange_element */



/* --------------------------------
 * p_add_frn_list
 * --------------------------------
 */
static void
p_add_frn_list(GapStoryRenderVidHandle *vidhand, GapStoryRenderFrameRangeElem *frn_elem)
{
  GapStoryRenderFrameRangeElem *frn_listend;


  if((vidhand)  && (frn_elem))
   {
     frn_listend = vidhand->frn_list;
     if (vidhand->frn_list == NULL)
     {
       /* 1. element (or returned list) starts frn_list */
       vidhand->frn_list = frn_elem;
     }
     else
     {
       /* link frn_elem (that can be a single ement or list) to the end of frn_list */
       frn_listend = vidhand->frn_list;
       while(frn_listend->next != NULL)
       {
          frn_listend = (GapStoryRenderFrameRangeElem *)frn_listend->next;
       }
       frn_listend->next = (GapStoryRenderFrameRangeElem *)frn_elem;
     }
   }
}  /* end p_add_frn_list */


/* ----------------------------------------------------
 * p_step_all_vtrack_attributes
 * ----------------------------------------------------
 */
static void
p_step_all_vtrack_attributes(gint32 track
                       , gint32 frames_to_handle
                       , GapStoryRenderVTrackArray *vtarr
                      )
{
  p_step_attribute( frames_to_handle
                  , &vtarr->attr[track].opacity_from
                  , &vtarr->attr[track].opacity_to
                  , &vtarr->attr[track].opacity_dur
                  );

  p_step_attribute( frames_to_handle
                  , &vtarr->attr[track].scale_x_from
                  , &vtarr->attr[track].scale_x_to
                  , &vtarr->attr[track].scale_x_dur
                  );

  p_step_attribute( frames_to_handle
                  , &vtarr->attr[track].scale_y_from
                  , &vtarr->attr[track].scale_y_to
                  , &vtarr->attr[track].scale_y_dur
                  );

  p_step_attribute( frames_to_handle
                  , &vtarr->attr[track].move_x_from
                  , &vtarr->attr[track].move_x_to
                  , &vtarr->attr[track].move_x_dur
                  );

  p_step_attribute( frames_to_handle
                  , &vtarr->attr[track].move_y_from
                  , &vtarr->attr[track].move_y_to
                  , &vtarr->attr[track].move_y_dur
                  );
}  /* end p_step_all_vtrack_attributes */                      


/* ----------------------------------------------------
 * p_set_vtrack_attributes
 * ----------------------------------------------------
 * set current video track attributes for the
 * Framerange_Element. from the current attribute array.
 *
 * attribute array is changed to the state after
 * the playback of the Framerange_element.
 *
 * Example for fade_in Attribute settings:
 *    IN:    opacity_from: 0.0   opacity_to: 1.0  opacity_dur: 50 frames
 *    if the range has 50 or more frames
 *    the fade_in can be handled fully within the range,
 *    the result will be:
 *       OUT:  opacity_from: 1.0   opacity_to: 1.0  opacity_dur: 0 frames
 *
 *    if the range is for example 25 frames (smaller than the duration 50)
 *    the result will be:
 *       OUT:  opacity_from: 0.5   opacity_to: 1.0  opacity_dur: 25 frames
 *       because there are 25 rest frames to complete the fade in action
 *       in the next range (if there will be any)
 *
 */
static void
p_set_vtrack_attributes(GapStoryRenderFrameRangeElem *frn_elem
                       ,GapStoryRenderVTrackArray *vtarr
                      )
{
  gint32 track;

  track = frn_elem->track;

  frn_elem->keep_proportions      = vtarr->attr[track].keep_proportions;
  frn_elem->fit_width             = vtarr->attr[track].fit_width;
  frn_elem->fit_height            = vtarr->attr[track].fit_height;
  frn_elem->mask_framecount       = vtarr->attr[track].mask_framecount;


  frn_elem->opacity_from     = vtarr->attr[track].opacity_from;
  frn_elem->opacity_to       = vtarr->attr[track].opacity_to;
  frn_elem->opacity_dur      = vtarr->attr[track].opacity_dur;
  frn_elem->scale_x_from     = vtarr->attr[track].scale_x_from;
  frn_elem->scale_x_to       = vtarr->attr[track].scale_x_to;
  frn_elem->scale_x_dur      = vtarr->attr[track].scale_x_dur;
  frn_elem->scale_y_from     = vtarr->attr[track].scale_y_from;
  frn_elem->scale_y_to       = vtarr->attr[track].scale_y_to;
  frn_elem->scale_y_dur      = vtarr->attr[track].scale_y_dur;
  frn_elem->move_x_from      = vtarr->attr[track].move_x_from;
  frn_elem->move_x_to        = vtarr->attr[track].move_x_to;
  frn_elem->move_x_dur       = vtarr->attr[track].move_x_dur;
  frn_elem->move_y_from      = vtarr->attr[track].move_y_from;
  frn_elem->move_y_to        = vtarr->attr[track].move_y_to;
  frn_elem->move_y_dur       = vtarr->attr[track].move_y_dur;


  /* advance mask_framecount */
  vtarr->attr[track].mask_framecount += frn_elem->frames_to_handle;


  p_step_all_vtrack_attributes(track, frn_elem->frames_to_handle, vtarr);
  

}  /* end p_set_vtrack_attributes  */




/* ---------------------------------
 * p_vidclip_add_as_is
 * ---------------------------------
 * set vtrack attribtes and add the frn_elem to the
 * list of videoclips (frn_list).
 * NOTE: the mask_framecount is set from current vattr context.
 */
static void
p_vidclip_add_as_is(GapStoryRenderFrameRangeElem *frn_elem
   ,GapStoryRenderVidHandle *vidhand
   ,GapStoryRenderVTrackArray *vtarr
   )
{
  if(frn_elem)
  {
    vtarr->attr[frn_elem->track].frame_count += frn_elem->frames_to_handle;
    p_set_vtrack_attributes(frn_elem, vtarr);
    p_add_frn_list(vidhand, frn_elem);

    if(gap_debug)
    {
      printf("#------------------ \n");
      gap_story_render_debug_print_frame_elem(frn_elem, -4);
      printf("\n#------------------ \n");
    }
  }
}  /* end p_vidclip_add_as_is */   


/* ---------------------------------
 * p_vidclip_shadow_add_silence
 * ---------------------------------
 */
static void
p_vidclip_shadow_add_silence(gint32 shadow_track
   ,gint32 fill_shadow_frames
   ,GapStoryRenderVidHandle *vidhand
   ,GapStoryRenderVTrackArray *vtarr
   ,const char *storyboard_file)
{
  GapStoryRenderFrameRangeElem *frn_elem;
  
  frn_elem = p_new_framerange_element(GAP_FRN_SILENCE
                                     , shadow_track
                                     , NULL            /* basename   */
                                     , NULL            /* extension  */
                                     , 1               /* frame_from */
                                     , fill_shadow_frames /* frame_to   */
                                     , storyboard_file
                                     , NULL            /* preferred_decoder */
                                     , NULL
                                     , vidhand->frn_list
                                     , vidhand->sterr
                                     , 1              /* seltrack */
                                     , 0              /* exact_seek*/
                                     , 0.0            /* delace */
				     , 1.0            /* step_density */
                                     , GAP_STB_FLIP_NONE    /* flip_request */
                                     , NULL                 /* mask_name */
                                     , 1.0                  /* mask_stepsize */
                                     , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                     , TRUE                 /* mask_disable */
                                     );
  if(frn_elem)
  {
    vtarr->attr[frn_elem->track].frame_count += frn_elem->frames_to_handle;
            p_set_vtrack_attributes(frn_elem, vtarr);
    /* do NOT step vtrack attributes
     * because ths fill operation with empty frames in the shadow track
     * creates frames before the current position and needs no current vtrack attributes
     * and MUST NOT change the current vattr settings.
     */
    p_add_frn_list(vidhand, frn_elem);
  }
}  /* end p_vidclip_shadow_add_silence */


/* ---------------------------------
 * p_recalculate_range_part
 * ---------------------------------
 * calculate a new from_frames and to_frames values
 * to reduce the clip length to the specified rest_frames.
 * lost_frames is an offest from the start.
 *
 *
 *  #########################################################
 *  |                   |                       |           | 
 *  |<-- lost_frames -->|<----- rest_frames --->|           | 
 *  |                                           |           | 
 *  |                                                       |
 *  |<--- frames_to_handle (before recalculate) ----------->|
 */
static void
p_recalculate_range_part(GapStoryRenderFrameRangeElem *frn_elem
   , gint32 lost_frames
   , gint32 rest_frames)
{
    gdouble l_offs_lost;
    gdouble l_offs_rest;
    gdouble l_orig_from;
    gdouble l_orig_to;
    gint32 l_orig_frames_to_handle;

    l_orig_from = frn_elem->frame_from;
    l_orig_to = frn_elem->frame_to;
    
    p_calculate_frames_to_handle(frn_elem);
    l_orig_frames_to_handle = frn_elem->frames_to_handle;
    
    if ((lost_frames + rest_frames) > l_orig_frames_to_handle)
    {
      printf("p_recalculate_range_part: ** ERROR cant split %d frames into parts of %d + %d\n"
          , (int)frn_elem->frames_to_handle
          , (int)lost_frames
          , (int)rest_frames
          );
      if(lost_frames > frn_elem->frames_to_handle)
      {
        return;
      }
      rest_frames = frn_elem->frames_to_handle - lost_frames;
    }

    l_offs_lost = (gdouble)lost_frames * frn_elem->step_density;
    l_offs_rest = (gdouble)(MAX(0,rest_frames -1)) * frn_elem->step_density;

    if(frn_elem->frame_to >= frn_elem->frame_from)
    {
      frn_elem->frame_from += l_offs_lost;
      frn_elem->frame_to = frn_elem->frame_from + l_offs_rest;
    }
    else
    {
      frn_elem->frame_from -= l_offs_lost;
      frn_elem->frame_to = frn_elem->frame_from - l_offs_rest;

      frn_elem->frame_from += 0.5;
      frn_elem->frame_to += 0.5;
    }

    p_calculate_frames_to_handle(frn_elem);


    if(gap_debug)
    {
      printf("\nRANGE PART (in): orig from:%.3f to:%.3f to_handle:%d   lost_frames:%d rest_frames:%d\n"
         , (float)l_orig_from
         , (float)l_orig_to
         , (int)l_orig_frames_to_handle
         , (int)lost_frames
         , (int)rest_frames
         );
      
      printf("RANGE PART (out): from:%f to:%f  offs_lost:%f offs_rest:%f  frames_to_handle: %d\n\n"
         , (float)frn_elem->frame_from
         , (float)frn_elem->frame_to
         , (float)l_offs_lost
         , (float)l_offs_rest
         , (int)frn_elem->frames_to_handle
         );
    }

    if(frn_elem->frames_to_handle != rest_frames)
    {
       if(gap_debug)
       {
         /* result may differ due to rounding 
          * in case step_density != 1.0 is used
          */
          printf("\n\nRANGE PART (dif) frames_to_handle != rest_frames due to rounding differences\n");
          printf("  ==> FORCE frames_to_handle: from caluclated value: %d forced value: %d\n\n"
            ,(int)frn_elem->frames_to_handle
            ,(int)rest_frames
            );
       }    
       frn_elem->frames_to_handle = rest_frames;
     
    }
    
}  /* end p_recalculate_range_part */

/* ---------------------------------
 * p_copy_vattr_values
 * ---------------------------------
 * copy video attribute values from specified src track
 * to specified dest track.
 * NOTE:
 *   the current frame_count and overlap_count are NOT copied!
 *   (typical use of this procedure is to transfer the settings
 *    from a normal track to a shadow track, where the counters
 *    must not be affected by the copy)
 */
static void
p_copy_vattr_values(gint32 src_track
                      , gint32 dst_track
                      , GapStoryRenderVTrackArray *vtarr
                      )
{
  vtarr->attr[dst_track].keep_proportions  = vtarr->attr[src_track].keep_proportions;
  vtarr->attr[dst_track].fit_width         = vtarr->attr[src_track].fit_width;
  vtarr->attr[dst_track].fit_height        = vtarr->attr[src_track].fit_height;


  vtarr->attr[dst_track].opacity_from      = vtarr->attr[src_track].opacity_from;
  vtarr->attr[dst_track].opacity_to        = vtarr->attr[src_track].opacity_to;
  vtarr->attr[dst_track].opacity_dur       = vtarr->attr[src_track].opacity_dur;
  vtarr->attr[dst_track].scale_x_from      = vtarr->attr[src_track].scale_x_from;
  vtarr->attr[dst_track].scale_x_to        = vtarr->attr[src_track].scale_x_to;
  vtarr->attr[dst_track].scale_x_dur       = vtarr->attr[src_track].scale_x_dur;
  vtarr->attr[dst_track].scale_y_from      = vtarr->attr[src_track].scale_y_from;
  vtarr->attr[dst_track].scale_y_to        = vtarr->attr[src_track].scale_y_to;
  vtarr->attr[dst_track].scale_y_dur       = vtarr->attr[src_track].scale_y_dur;
  vtarr->attr[dst_track].move_x_from       = vtarr->attr[src_track].move_x_from;
  vtarr->attr[dst_track].move_x_to         = vtarr->attr[src_track].move_x_to;
  vtarr->attr[dst_track].move_x_dur        = vtarr->attr[src_track].move_x_dur;
  vtarr->attr[dst_track].move_y_from       = vtarr->attr[src_track].move_y_from;
  vtarr->attr[dst_track].move_y_to         = vtarr->attr[src_track].move_y_to;
  vtarr->attr[dst_track].move_y_dur        = vtarr->attr[src_track].move_y_dur;
  
}  /* end p_copy_vattr_values */


/* ---------------------------------
 * p_vidclip_split_and_add_frn_list
 * ---------------------------------
 * split the current clip into parts used for overlap in the shadow track
 * and remaining part in the normal track.
 * if the required amount of overlaping frames is not available in this
 * currently handled clip, the splitting will continue in the following
 * clips later on. In this case there will be no remaning part.
 * In some rare cases the current clip is completely thrown away
 * because the needed amount for overlapping will be fetched from
 * one of the following handled clips.
 */
static void
p_vidclip_split_and_add_frn_list(GapStoryRenderFrameRangeElem *frn_elem
   ,GapStoryRenderVidHandle *vidhand
   ,GapStoryRenderVTrackArray *vtarr
   ,const char *storyboard_file)
{
  gint32 l_track;
  gint32 l_shadow_track;
  gint32 l_shadow_frames_free;
  gint32 l_cut_frames;           /* frames cut off from start of this video clip */
  gint32 l_overlap_frames;       /* overlapping frames handled by this video clip */
  gint32 l_fill_shadow_frames;   /* requred empty frames to fill up shadow track */
  gint32 l_lost_frames;          /* frames in this clip thrown away because no space in shadow track */
  gint32 l_remain_frames;        /* frames reamaining to be placed in normal track */
  gint32 l_dead_frames;          /* frames in this clip and further clips thrown away because no space in shadow track */
  gint32 l_need_frames;          /* required number of frames to overlap */

  l_track = frn_elem->track;
  l_shadow_track = l_track - 1;
 
  l_shadow_frames_free = MAX(0, (vtarr->attr[l_track].frame_count
                       - vtarr->attr[l_shadow_track].frame_count));
  
  
  l_cut_frames = MIN(vtarr->attr[l_track].overlap_count, frn_elem->frames_to_handle);
  l_fill_shadow_frames =
      MAX(0, 
           ((vtarr->attr[l_track].frame_count
             - vtarr->attr[l_track].overlap_count)
             - vtarr->attr[l_shadow_track].frame_count)
          );
  l_need_frames = MAX(0, (l_shadow_frames_free - l_fill_shadow_frames));
  l_dead_frames = vtarr->attr[l_track].overlap_count - l_need_frames;
  l_overlap_frames = MAX(0, (l_cut_frames - l_dead_frames));
  
  l_lost_frames = l_cut_frames - l_overlap_frames;
  l_remain_frames = frn_elem->frames_to_handle - l_cut_frames;

  if(gap_debug)
  {
    printf("SPLIT: free_shadow:%d fill_shadow:%d  need:%d dead:%d cut: %d, overlap:%d, lost:%d remain:%d\n"
       , (int)l_shadow_frames_free
       , (int)l_fill_shadow_frames
       , (int)l_need_frames
       , (int)l_dead_frames
       , (int)l_cut_frames
       , (int)l_overlap_frames
       , (int)l_lost_frames
       , (int)l_remain_frames
       );

  }


  if(l_fill_shadow_frames > 0)
  {
    p_vidclip_shadow_add_silence(l_shadow_track
             , l_fill_shadow_frames
             , vidhand
             , vtarr
             , storyboard_file
             );
    /* reset mask_framecount in shadow track to 0  */
    vtarr->attr[l_shadow_track].mask_framecount = 0;
  }                    
  
  if(l_overlap_frames > 0)
  {
    GapStoryRenderFrameRangeElem *frn_elem_dup;

    /* shadow track shall continue with current vatt settings
     * of the corresponding normal track
     */    
    p_copy_vattr_values(l_track          /* source */
                       ,l_shadow_track   /* destination */
                       ,vtarr
                       );
    
    /* create a copy for the shadow track */
    frn_elem_dup = p_new_framerange_element(frn_elem->frn_type
                      ,l_shadow_track
                      ,frn_elem->basename
                      ,frn_elem->ext
                      ,frn_elem->frame_from
                      ,frn_elem->frame_to
                      ,storyboard_file
                      ,vidhand->preferred_decoder
                      ,frn_elem->filtermacro_file
                      ,vidhand->frn_list
                      ,vidhand->sterr
                      ,frn_elem->seltrack
                      ,frn_elem->exact_seek
                      ,frn_elem->delace
                      ,frn_elem->step_density
                      ,frn_elem->flip_request
                      ,frn_elem->mask_name
                      ,frn_elem->mask_stepsize
                      ,frn_elem->mask_anchor
                      ,FALSE     /* keep mask enabled if the element has one */
                      );
                                           
    
    p_recalculate_range_part(frn_elem_dup
                            ,l_lost_frames
                            ,l_overlap_frames
                            );
    p_vidclip_add_as_is(frn_elem_dup, vidhand, vtarr);
    
    /* copy vattr settings back from shadow track to normal track
     * (after the overlapping frames were processed in the
     * shadow track), the normal track will continue with settings
     * changed by shadow track processing
     */    
    p_copy_vattr_values(l_shadow_track   /* source */
                       ,l_track          /* destination */
                       ,vtarr
                       );
 
    /* continue mask_framecount in normal track (that has started in the shadow track) */
    vtarr->attr[l_track].mask_framecount = vtarr->attr[l_shadow_track].mask_framecount;

    /* decrement overlap_count by */
    vtarr->attr[l_track].overlap_count -= l_cut_frames;
  }


  if(l_remain_frames > 0)
  {
    p_recalculate_range_part(frn_elem
                            ,l_cut_frames
                            ,l_remain_frames
                            );
    p_vidclip_add_as_is(frn_elem, vidhand, vtarr);
  }

}  /* end p_vidclip_split_and_add_frn_list */



/* ---------------------------------
 * p_vidclip_add
 * ---------------------------------
 * set vtrack attribtes and add the frn_elem to the
 * list of videoclips (frn_list)
 * Overlapping is handled by splitting th video clip
 * into appropriate parts, where the overlapping frames
 * are placed into the shadow track.
 */
static void
p_vidclip_add(GapStoryRenderFrameRangeElem *frn_elem
   ,GapStoryRenderVidHandle *vidhand
   ,GapStoryRenderVTrackArray *vtarr
   ,const char *storyboard_file
   ,gboolean first_of_group
   )
{
  if(frn_elem == NULL)
  {
    return;
  }



  if(vtarr->attr[frn_elem->track].overlap_count > 0)
  {
    if(first_of_group)
    {
      /* reset mask frame progress to 0 in the shadow track */
      vtarr->attr[frn_elem->track -1].mask_framecount = 0;   /* shadow track */
    }
    /* an overlap transition is pending
     * have to split off the overlapping frame part
     * to the shadow track, the rest will be added to
     * the normal track
     */
    p_vidclip_split_and_add_frn_list(frn_elem, vidhand, vtarr, storyboard_file);
  }
  else
  {
    if(first_of_group)
    {
      /* reset mask frame progress to 0 before processing each parsed clip.
       * the mask_framecount handles clip internal start value for fetching layer mask frames
       * in case were the scanned clip is splitted internally
       * (due to repetitions, pingpong mode, or overlapping)
       * the splitted parts 2 up to N will have mask_framecount > 0
       */
      vtarr->attr[frn_elem->track].mask_framecount = 0;
    }
    /* normal scenario without shadow track overlapping
     * simply add the video clip 1:1 to the list
     */
    p_vidclip_add_as_is(frn_elem, vidhand, vtarr);
  }

}  /* end p_vidclip_add */



/* ----------------------------------------------------
 * p_storyboard_analyze
 * ----------------------------------------------------
 * this procedure checks the storyboard in RAM (GapStoryBoard *stb)
 * and converts all elements to the
 * corresponding rangelist structures (audio or frames or attr tables)
 */
static void
p_storyboard_analyze(GapStoryBoard *stb
                      , GapStoryRenderVTrackArray *vtarr
                      , GapStoryRenderVidHandle *vidhand
                      )
{
  GapStoryElem *stb_elem;
  char *storyboard_file;

  GapStoryRenderAudioRangeElem *aud_elem;
  GapStoryRenderFrameRangeElem *frn_elem;
  GapStoryRenderFrameRangeElem *frn_list;
  GapStoryRenderFrameRangeElem *frn_pinglist;
  GapStoryRenderErrors         *sterr;
  GapStoryRenderFrameRangeElem *frn_known_list;

  gint32 l_track;
  gint   l_idx;
  gint32 l_max_elems;
  gint32 l_cnt_elems;

  sterr=vidhand->sterr;
  frn_list = NULL;

  storyboard_file = stb->storyboardfile;

  /* copy Master informations: */
  if(stb->master_width > 0)
  {
    vidhand->master_width     = stb->master_width;
    vidhand->master_height    = stb->master_height;
  }
  if(stb->master_framerate > 0)
  {
    vidhand->master_framerate = stb->master_framerate;
  }
  vidhand->preferred_decoder = NULL;
  if(stb->preferred_decoder)
  {
    vidhand->preferred_decoder = g_strdup(stb->preferred_decoder);
  }

  if(stb->master_volume >= 0)
  {
    vidhand->master_volume = stb->master_volume;
  }
  if(stb->master_samplerate > 0)
  {
    vidhand->master_samplerate = stb->master_samplerate;
  }

  /* cont Elements in the STB */
  l_max_elems = 0;
  for(stb_elem = stb->stb_elem; stb_elem != NULL;  stb_elem = stb_elem->next)
  {
    l_max_elems++;
  }

  /* Loop foreach Element in the STB */
  l_cnt_elems = 0;
  for(stb_elem = stb->stb_elem; stb_elem != NULL;  stb_elem = stb_elem->next)
  {
    if(stb_elem->track == GAP_STB_MASK_TRACK_NUMBER)
    {
      /* ignore mask definitions, in the reserved GAP_STB_MASK_TRACK_NUMBER track
       * in this loop,
       * mask definitions are handled separately.
       */
      continue;
    }
    l_track    = 1 + (2 * MAX((stb_elem->track -1), 0));
    frn_known_list  = vidhand->frn_list;
    
    /* reset mask frame progress to 1 before processing each parsed clip.
     * the mask_framecount handles clip internal start value for fetchin layer mask frames
     * in case were the scanned clip is splitted internally
     * (due to repetitions, pingpong mode, or overlapping)
     * the splitted parts 2 up to N will have mask_framecount > 0
     */
    vtarr->attr[l_track].mask_framecount = 0;
  
    switch(stb_elem->record_type)
    {
      case GAP_STBREC_ATT_TRANSITION:
        {
          gint ii;

          vtarr->attr[l_track].overlap_count    += MAX(stb_elem->att_overlap, 0);
          vtarr->attr[l_track].fit_width        = stb_elem->att_fit_width;
          vtarr->attr[l_track].fit_height       = stb_elem->att_fit_height;
          vtarr->attr[l_track].keep_proportions = stb_elem->att_keep_proportions;
          for(ii=0; ii < GAP_STB_ATT_TYPES_ARRAY_MAX; ii++)
          {
            if(stb_elem->att_arr_enable[ii])
            {
              switch(ii)
              {
                case GAP_STB_ATT_TYPE_OPACITY:
                  vtarr->attr[l_track].opacity_from = stb_elem->att_arr_value_from[ii];
                  vtarr->attr[l_track].opacity_to   = stb_elem->att_arr_value_to[ii];
                  vtarr->attr[l_track].opacity_dur  = stb_elem->att_arr_value_dur[ii];
                  break;
                case GAP_STB_ATT_TYPE_MOVE_X:
                  vtarr->attr[l_track].move_x_from  = stb_elem->att_arr_value_from[ii];
                  vtarr->attr[l_track].move_x_to    = stb_elem->att_arr_value_to[ii];
                  vtarr->attr[l_track].move_x_dur   = stb_elem->att_arr_value_dur[ii];
                  break;
                case GAP_STB_ATT_TYPE_MOVE_Y:
                  vtarr->attr[l_track].move_y_from  = stb_elem->att_arr_value_from[ii];
                  vtarr->attr[l_track].move_y_to    = stb_elem->att_arr_value_to[ii];
                  vtarr->attr[l_track].move_y_dur   = stb_elem->att_arr_value_dur[ii];
                  break;
                case GAP_STB_ATT_TYPE_ZOOM_X:
                  vtarr->attr[l_track].scale_x_from = stb_elem->att_arr_value_from[ii];
                  vtarr->attr[l_track].scale_x_to   = stb_elem->att_arr_value_to[ii];
                  vtarr->attr[l_track].scale_x_dur  = stb_elem->att_arr_value_dur[ii];
                  break;
                case GAP_STB_ATT_TYPE_ZOOM_Y:
                  vtarr->attr[l_track].scale_y_from = stb_elem->att_arr_value_from[ii];
                  vtarr->attr[l_track].scale_y_to   = stb_elem->att_arr_value_to[ii];
                  vtarr->attr[l_track].scale_y_dur  = stb_elem->att_arr_value_dur[ii];
                  break;
              }
            }
          }

        }
        break;
      case GAP_STBREC_VID_SILENCE:
        if(!vidhand->ignore_video)
        {
          /* add framerange element for the current storyboard_file line */
          frn_elem = p_new_framerange_element(GAP_FRN_SILENCE
                                             , l_track
                                             , NULL            /* basename   */
                                             , NULL            /* extension  */
                                             , 1               /* frame_from */
                                             , stb_elem->nloop /* frame_to   */
                                             , storyboard_file
                                             , NULL            /* preferred_decoder */
                                             , NULL
                                             , frn_known_list
                                             , sterr
                                             , 1              /* seltrack */
                                             , 0              /* exact_seek*/
                                             , 0.0            /* delace */
					     , 1.0            /* step_density */
                                             , GAP_STB_FLIP_NONE    /* flip_request */
                                             , NULL                 /* mask_name */
                                             , 1.0                  /* mask_stepsize */
                                             , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                             , TRUE                 /* mask_disable */
                                             );
          if(frn_elem)
          {
            frn_elem->wait_untiltime_sec = stb_elem->vid_wait_untiltime_sec;
            frn_elem->wait_untilframes = stb_elem->vid_wait_untiltime_sec * vidhand->master_framerate;

            p_vidclip_add(frn_elem, vidhand, vtarr, storyboard_file, TRUE);
          }
        }
        break;
      case GAP_STBREC_VID_COLOR:
        if(!vidhand->ignore_video)
        {
          /* add framerange element for the current storyboard_file line */
          frn_elem = p_new_framerange_element(GAP_FRN_COLOR
                                             , l_track
                                             , NULL
                                             , NULL            /* extension  */
                                             , 1               /* frame_from */
                                             , stb_elem->nloop /* frame_to   */
                                             , storyboard_file
                                             , NULL            /* referred_decoder */
                                             , NULL
                                             , frn_known_list
                                             , sterr
                                             , 1              /* seltrack */
                                             , 0              /* exact_seek*/
                                             , 0.0            /* delace */
					     , 1.0            /* step_density */
                                             , stb_elem->flip_request
                                             , stb_elem->mask_name
                                             , stb_elem->mask_stepsize
                                             , stb_elem->mask_anchor
                                             , stb_elem->mask_disable
                                             );
          if(frn_elem)
          {
            frn_elem->red_f           = CLAMP(stb_elem->color_red,   0.0, 1.0);     
            frn_elem->green_f         = CLAMP(stb_elem->color_green, 0.0, 1.0);     
            frn_elem->blue_f          = CLAMP(stb_elem->color_blue,  0.0, 1.0);     
            frn_elem->alpha_f         = CLAMP(stb_elem->color_alpha, 0.0, 1.0);     

            p_vidclip_add(frn_elem, vidhand, vtarr, storyboard_file, TRUE);
          }
        }
        break;
      case GAP_STBREC_VID_IMAGE:
        if(!vidhand->ignore_video)
        {
          /* add framerange element for the current storyboard_file line */
          frn_elem = p_new_framerange_element(GAP_FRN_IMAGE
                                             , l_track
                                             , stb_elem->orig_filename
                                             , NULL            /* extension  */
                                             , 1               /* frame_from */
                                             , stb_elem->nloop /* frame_to   */
                                             , storyboard_file
                                             , vidhand->preferred_decoder
                                             , stb_elem->filtermacro_file
                                             , frn_known_list
                                             , sterr
                                             , 1              /* seltrack */
                                             , 0              /* exact_seek*/
                                             , 0.0            /* delace */
					     , 1.0            /* step_density */
                                             , stb_elem->flip_request
                                             , stb_elem->mask_name
                                             , stb_elem->mask_stepsize
                                             , stb_elem->mask_anchor
                                             , stb_elem->mask_disable
                                             );
          if(frn_elem)
          {
            p_vidclip_add(frn_elem, vidhand, vtarr, storyboard_file, TRUE);
          }
        }
        break;
      case GAP_STBREC_VID_ANIMIMAGE:
      case GAP_STBREC_VID_FRAMES:
      case GAP_STBREC_VID_MOVIE:
        if(!vidhand->ignore_video)
        {
           GapStoryRenderFrameType        l_frn_type;
           gint32   l_repcnt;
           gint32   l_sub_from;
           gint32   l_sub_to;
           gint     l_pingpong;
           char    *l_file_or_basename;
           char    *l_ext_ptr;
           gboolean first_of_group;
          
           l_ext_ptr = NULL;
           l_file_or_basename = stb_elem->orig_filename;
           l_pingpong = 1;
           if(stb_elem->playmode == GAP_STB_PM_PINGPONG)
           {
             l_pingpong = 2;
           }
           
           l_frn_type = GAP_FRN_ANIMIMAGE;
           switch(stb_elem->record_type)
           {
             case GAP_STBREC_VID_ANIMIMAGE:
               l_frn_type = GAP_FRN_ANIMIMAGE;
               l_file_or_basename = stb_elem->orig_filename;
               break;
             case GAP_STBREC_VID_FRAMES:
               l_frn_type = GAP_FRN_FRAMES;
               l_ext_ptr = stb_elem->ext;
               l_file_or_basename = stb_elem->basename;
               break;
             case GAP_STBREC_VID_MOVIE:
               l_frn_type = GAP_FRN_MOVIE;
               l_file_or_basename = stb_elem->orig_filename;
               break;
	     default:
	       break;  /* should never be reached */
           }

           frn_pinglist = frn_known_list;
           first_of_group = TRUE;
           /* expand element according to pingpong and nloop settings  */
           for(l_repcnt=0; l_repcnt < stb_elem->nloop; l_repcnt++)
           {
             l_sub_from = stb_elem->from_frame;
             l_sub_to   = stb_elem->to_frame;
             for(l_idx=0; l_idx < l_pingpong; l_idx++)
             {
               /* add framerange element for the current storyboard_file line */
               frn_elem = p_new_framerange_element( l_frn_type
                                                  , l_track
                                                  , l_file_or_basename
                                                  , l_ext_ptr
                                                  , l_sub_from
                                                  , l_sub_to
                                                  , storyboard_file
                                                  , gap_story_get_preferred_decoder(stb, stb_elem)
                                                  , stb_elem->filtermacro_file
                                                  , frn_pinglist
                                                  , sterr
                                                  , stb_elem->seltrack
                                                  , stb_elem->exact_seek
                                                  , stb_elem->delace
						  , stb_elem->step_density
                                                  , stb_elem->flip_request
                                                  , stb_elem->mask_name
                                                  , stb_elem->mask_stepsize
                                                  , stb_elem->mask_anchor
                                                  , stb_elem->mask_disable
                                                  );
               if(frn_elem)
               {
                 /* prepare for pingpong mode with inverted range,
                  * omitting the start/end frames 
                  */
                 l_sub_from = frn_elem->frame_to   - frn_elem->delta;
                 l_sub_to   = frn_elem->frame_from + frn_elem->delta;

                 p_vidclip_add(frn_elem, vidhand, vtarr, storyboard_file, first_of_group);

                 first_of_group = FALSE;
                 frn_pinglist = frn_list;

               }
             }
           }


        }
        break;
      case GAP_STBREC_AUD_SILENCE:
        if(!vidhand->ignore_audio)
        {
          /* add audiorange element for the current storyboard_file line */
          aud_elem = gap_story_render_audio_new_audiorange_element(GAP_AUT_SILENCE
                                             , l_track
                                             , NULL
                                             , vidhand->master_samplerate
                                             , 0              /* from_sec     */
                                             , stb_elem->aud_play_to_sec      /* to_sec       */
                                             , 0.0            /* vol_start    */
                                             , 0.0            /* volume       */
                                             , 0.0            /* vol_end      */
                                             , 0.0            /* fade_in_sec  */
                                             , 0.0            /* fade_out_sec */
                                             , vidhand->util_sox
                                             , vidhand->util_sox_options
                                             , storyboard_file
                                             , vidhand->preferred_decoder
                                             , vidhand->aud_list  /* known audio range elements */
                                             , sterr
                                             , 1              /* seltrack */
					     , vidhand->create_audio_tmp_files
					     , 0.0 /* min_play_sec */
					     , 0.0 /* max_play_sec */
					     , vidhand
                                             );
          if(aud_elem)
          {
             aud_elem->wait_untiltime_sec = stb_elem->aud_wait_untiltime_sec;
             aud_elem->wait_until_samples = stb_elem->aud_wait_untiltime_sec * aud_elem->samplerate;
             gap_story_render_audio_add_aud_list(vidhand, aud_elem);
          }
        }
        break;
      case GAP_STBREC_AUD_SOUND:
      case GAP_STBREC_AUD_MOVIE:
        if(!vidhand->ignore_audio)
        {
          GapStoryRenderAudioType  l_aud_type;
          gint     l_rix;

          if(stb_elem->record_type == GAP_STBREC_AUD_SOUND)
          {
            l_aud_type = GAP_AUT_AUDIOFILE;
          }
          else
          {
            l_aud_type = GAP_AUT_MOVIE;
          }

          for(l_rix=0; l_rix < stb_elem->nloop; l_rix++)
          {
            /* add audiorange element for the current storyboard_file line */
            aud_elem = gap_story_render_audio_new_audiorange_element(l_aud_type  /* GAP_AUT_MOVIE or GAP_AUT_AUDIOFILE */
                                           , l_track
                                           , stb_elem->aud_filename
                                           , vidhand->master_samplerate
                                           , stb_elem->aud_play_from_sec
                                           , stb_elem->aud_play_to_sec
                                           , stb_elem->aud_volume_start
                                           , stb_elem->aud_volume
                                           , stb_elem->aud_volume_end
                                           , stb_elem->aud_fade_in_sec
                                           , stb_elem->aud_fade_out_sec
                                           , vidhand->util_sox
                                           , vidhand->util_sox_options
                                           , storyboard_file
                                           , gap_story_get_preferred_decoder(stb, stb_elem)
                                           , vidhand->aud_list  /* known audio range elements */
                                           , sterr
                                           , stb_elem->aud_seltrack
					   , vidhand->create_audio_tmp_files
					   , stb_elem->aud_min_play_sec
					   , stb_elem->aud_max_play_sec
					   , vidhand
                                           );
            if(aud_elem)
            {
              gap_story_render_audio_add_aud_list(vidhand, aud_elem);
            }
	  }
        }
        break;
      default:
        break;
    }

    /* progress handling */
    l_cnt_elems++;
    
    *vidhand->progress = (gdouble)l_cnt_elems / (gdouble)l_max_elems;
    if(vidhand->status_msg)
    {
      g_snprintf(vidhand->status_msg, vidhand->status_msg_len
                , _("analyze line %d (out of %d)")
		, (int)l_cnt_elems
		, (int)l_max_elems
		);
    }


  }  /* END Loop foreach Element in the STB */

}       /* end p_storyboard_analyze */


/* ----------------------------------------------------
 * p_framerange_list_from_storyboard
 * ----------------------------------------------------
 * this procedure builds up a framerange list
 * from the  given storyboard structure in MEMORY
 * or by parsing the specified storyboard_file.
 *
 * return the framerange_list (scanned from storyboard or storyboard_file)
 */
static GapStoryRenderFrameRangeElem *
p_framerange_list_from_storyboard(const char *storyboard_file
                      ,gint32 *frame_count
                      ,GapStoryRenderVidHandle *vidhand
                      ,GapStoryBoard *stb_mem_ptr
                      )
{
  GapStoryRenderVTrackArray        vtarray;
  GapStoryRenderVTrackArray       *vtarr;
  GapStoryRenderErrors            *sterr;
  gint   l_idx;

  sterr=vidhand->sterr;
  *frame_count = 0;
  vtarr = &vtarray;
  vtarr->max_tracknum = GAP_STB_MAX_VID_INTERNAL_TRACKS -1;

  /* clear video track attribute settings for all tracks */
  for(l_idx=0; l_idx <= vtarr->max_tracknum; l_idx++)
  {
    vtarr->attr[l_idx].frame_count   = 0;
    vtarr->attr[l_idx].overlap_count = 0;
    vtarr->attr[l_idx].mask_framecount = 0;

    vtarr->attr[l_idx].keep_proportions   = FALSE;
    vtarr->attr[l_idx].fit_width          = TRUE;
    vtarr->attr[l_idx].fit_height         = TRUE;
    vtarr->attr[l_idx].opacity_from  = 1.0;
    vtarr->attr[l_idx].opacity_to    = 1.0;
    vtarr->attr[l_idx].opacity_dur   = 0;
    vtarr->attr[l_idx].scale_x_from  = 1.0;
    vtarr->attr[l_idx].scale_x_to    = 1.0;
    vtarr->attr[l_idx].scale_x_dur   = 0;
    vtarr->attr[l_idx].scale_y_from  = 1.0;
    vtarr->attr[l_idx].scale_y_to    = 1.0;
    vtarr->attr[l_idx].scale_y_dur   = 0;
    vtarr->attr[l_idx].move_x_from   = 0.0;
    vtarr->attr[l_idx].move_x_to     = 0.0;
    vtarr->attr[l_idx].move_x_dur    = 0;
    vtarr->attr[l_idx].move_y_from   = 0.0;
    vtarr->attr[l_idx].move_y_to     = 0.0;
    vtarr->attr[l_idx].move_y_dur    = 0;
  }



  /* convert from GapStoryBoard to render representation
   * of the storyboard.
   */
  {
    GapStoryBoard *stb;

    stb = NULL;

    if(stb_mem_ptr)
    {
      /* we have a storyboard already available in MEMORY */
      stb = gap_story_duplicate(stb_mem_ptr);
    }
    
    if(stb == NULL)
    {
      /* load and parse the storyboard structure from file */
      stb = gap_story_parse(storyboard_file);
    }
    
    if(stb)
    {
      if(stb->errtext != NULL)
      {
	/* report the 1.st error */
	sterr->curr_nr  = stb->errline_nr;
	sterr->currline = stb->errline;
        p_set_stb_error(sterr, stb->errtext);
      }
      else
      {
        /* findout min and max playtime for audio clip references
         * that are to extract from videofiles
         */
        gap_story_set_aud_movie_min_max(stb);
        
        /* analyze the stb list and transform this list
	 * to vidhand->frn_list and vidhand->aud_list
	 */
        p_storyboard_analyze(stb
                            ,vtarr
                            ,vidhand
                            );

        /* mask definitions */
        p_copy_mask_definitions_to_vidhand(stb, vidhand);
      }
      gap_story_free_storyboard(&stb);
      
    }
  }


  if(vidhand->frn_list)
  {
    /* findout total frame_count (is the max frame_count of all tracks) */
    for(l_idx=0; l_idx <= vtarr->max_tracknum; l_idx++)
    {
      if (*frame_count < vtarr->attr[l_idx].frame_count)
      {
        *frame_count = vtarr->attr[l_idx].frame_count;
      }
    }
  }
  else
  {
    *frame_count = 0;
    sterr->currline = "(eof)";

    p_set_stb_error(sterr, _("No Frames or Images found ...."));
  }

  return (vidhand->frn_list);
}       /* end p_framerange_list_from_storyboard */


/* ----------------------------------------------------
 * p_free_framerange_list
 * ----------------------------------------------------
 */
static void
p_free_framerange_list(GapStoryRenderFrameRangeElem * frn_list)
{
  GapStoryRenderFrameRangeElem *frn_elem;
  GapStoryRenderFrameRangeElem *frn_next;

  for(frn_elem = frn_list; frn_elem != NULL; frn_elem = frn_next)
  {
    if(frn_elem->basename)          { g_free(frn_elem->basename);}
    if(frn_elem->ext)               { g_free(frn_elem->ext);}
    if(frn_elem->filtermacro_file)  { g_free(frn_elem->filtermacro_file);}

    if(frn_elem->gvahand)           { GVA_close(frn_elem->gvahand);}

    frn_next = (GapStoryRenderFrameRangeElem *)frn_elem->next;
    g_free(frn_elem);
  }
}       /* end p_free_framerange_list */


 
/* ----------------------------------------------------
 * p_open_mask_vidhand
 * ----------------------------------------------------
 */
static void
p_open_mask_vidhand(GapStoryElem *stb_elem, GapStoryRenderMaskDefElem *maskdef_elem)
{
  GapLibTypeInputRange input_mode;
  
  input_mode = GAP_RNGTYPE_IMAGE;
  switch(stb_elem->record_type)
  {
    case GAP_STBREC_VID_IMAGE:
      input_mode = GAP_RNGTYPE_IMAGE;
      break;
    case GAP_STBREC_VID_ANIMIMAGE:
      input_mode = GAP_RNGTYPE_LAYER;
      break;
    case GAP_STBREC_VID_FRAMES:
      input_mode = GAP_RNGTYPE_FRAMES;
      break;
    case GAP_STBREC_VID_MOVIE:
      input_mode = GAP_RNGTYPE_MOVIE;
      break;
    default:
      break;
  }


  if(gap_debug)
  {
    printf("p_open_mask_vidhand: MASK_ELEM\n");
    gap_story_debug_print_elem(stb_elem);
  }
  
  maskdef_elem->mask_vidhand = p_open_video_handle_private( TRUE         /* ignore_audio */
                            , FALSE        /* dont ignore_video */
                            , FALSE        /* create_audio_tmp_files */
                            , NULL         /* progress_ptr */
                            , NULL         /* status_msg */
                            , 0            /* status_msg_len */
                            , NULL         /* storyboard_file */
                            ,stb_elem->basename
                            ,stb_elem->ext
                            ,stb_elem->from_frame
                            ,stb_elem->to_frame
                            ,&maskdef_elem->frame_count
                            ,FALSE                      /* do_gimp_progress */
			    ,input_mode
			    ,stb_elem->orig_filename    /* imagename */
                            ,stb_elem->preferred_decoder
                            ,stb_elem->seltrack
                            ,stb_elem->exact_seek
                            ,stb_elem->delace
                            ,FALSE                      /* compensate_framerange */
                            ,NULL                       /* stb_mem_ptr */
                            );
  if(maskdef_elem->mask_vidhand)
  {
    maskdef_elem->mask_vidhand->is_mask_handle = TRUE;
  }
}  /* end p_open_mask_vidhand */



/* ----------------------------------------------------
 * p_copy_mask_definitions
 * ----------------------------------------------------
 * copy mask definitions and open a sub GapStoryRenderVidHandle
 * for each mask definition.
 * those handles are used to fetch masks from any type of clips.
 */
static void
p_copy_mask_definitions_to_vidhand(GapStoryBoard *stb_ptr, GapStoryRenderVidHandle *vidhand)
{
  GapStoryElem *stb_elem;
  vidhand->maskdef_elem = NULL; /* start with empty mask definition list */
  
  for(stb_elem = stb_ptr->stb_elem; stb_elem != NULL;  stb_elem = stb_elem->next)
  {
    if(stb_elem->track != GAP_STB_MASK_TRACK_NUMBER)
    {
      continue;
    }
    if(stb_elem->mask_name)
    {
      GapStoryRenderMaskDefElem *maskdef_elem;
      GapStoryElem      *stb_elem_ref;

      /* check if there are references to this mask definition */
      stb_elem_ref = gap_story_find_mask_reference_by_name(stb_ptr, stb_elem->mask_name);
      if(stb_elem_ref == NULL)
      {
        /* this mask definition is not refered,
         * no processing is necessary
         */
        continue;
      }
      
      if(gap_debug)
      {
        printf("p_copy_mask_definitions_to_vidhand: \n");
        gap_story_debug_print_elem(stb_elem);
      }


      maskdef_elem = g_new(GapStoryRenderMaskDefElem, 1);
      if(maskdef_elem)
      {
          maskdef_elem->mask_name = g_strdup(stb_elem->mask_name);
          maskdef_elem->record_type = (gint32)stb_elem->record_type;
          maskdef_elem->frame_count = 0;
          maskdef_elem->flip_request = stb_elem->flip_request;
          maskdef_elem->mask_vidhand = NULL;
          maskdef_elem->next = NULL;

          p_open_mask_vidhand(stb_elem, maskdef_elem);

          /* link mask definition element as 1st element to the list */
          vidhand->maskdef_elem = maskdef_elem;
      }
    }
  }

}  /* end p_copy_mask_definitions */


/* ----------------------------------------------------
 * p_free_mask_definitions
 * ----------------------------------------------------
 * copy mask definitions and open a sub GapStoryRenderVidHandle
 * for each mask definition.
 */
static void
p_free_mask_definitions(GapStoryRenderVidHandle *vidhand)
{
  GapStoryRenderMaskDefElem *maskdef_elem;
  GapStoryRenderMaskDefElem *maskdef_next;
  
  for(maskdef_elem = vidhand->maskdef_elem; maskdef_elem != NULL;  maskdef_elem = maskdef_next)
  {
    if(maskdef_elem->mask_vidhand)
    {
      gap_story_render_close_vid_handle(maskdef_elem->mask_vidhand);
    }
    if(maskdef_elem->mask_name)
    {
      g_free(maskdef_elem->mask_name);
    }

    maskdef_next = maskdef_elem->next;
    g_free(maskdef_elem);
  }

}  /* end p_copy_mask_definitions */



/* ----------------------------------------------------
 * gap_story_render_close_vid_handle
 * ----------------------------------------------------
 * close video handle (free framelist and errors)
 */
void
gap_story_render_close_vid_handle(GapStoryRenderVidHandle *vidhand)
{
   p_free_framerange_list(vidhand->frn_list);
   p_free_stb_error(vidhand->sterr);
   p_free_mask_definitions(vidhand);

   vidhand->frn_list = NULL;
   vidhand->sterr = NULL;
}  /* end gap_story_render_close_vid_handle */


/* ----------------------------------------------------
 * gap_story_render_set_audio_resampling_program
 * ----------------------------------------------------
 */
void
gap_story_render_set_audio_resampling_program(GapStoryRenderVidHandle *vidhand
                           , char *util_sox
                           , char *util_sox_options
                           )
{
  if(vidhand)
  {
     if(vidhand->util_sox)
     {
       g_free(vidhand->util_sox);
       vidhand->util_sox = NULL;
     }
     if(vidhand->util_sox_options)
     {
       g_free(vidhand->util_sox_options);
       vidhand->util_sox_options = NULL;
     }

     if(util_sox)
     {
       vidhand->util_sox = g_strdup(util_sox);
     }
     if(util_sox_options)
     {
       vidhand->util_sox_options = g_strdup(util_sox_options);
     }

  }
}  /* end gap_story_render_set_audio_resampling_program */


/* ----------------------------------------------------
 * p_find_maskdef_by_name
 * ----------------------------------------------------
 */
static GapStoryRenderMaskDefElem *
p_find_maskdef_by_name(GapStoryRenderVidHandle *vidhand, const char *mask_name)
{
  GapStoryRenderMaskDefElem *maskdef_elem;
  
  for(maskdef_elem = vidhand->maskdef_elem; maskdef_elem != NULL;  maskdef_elem = maskdef_elem->next)
  {
    if(strcmp(maskdef_elem->mask_name, mask_name) == 0)
    {
      return(maskdef_elem);
    }
  }
  return (NULL);

}  /* end p_find_maskdef_by_name */


/* ----------------------------------------------------
 * p_mask_image_fetcher
 * ----------------------------------------------------
 * fetch specified mask frame as gray image with only one composite layer.
 * if the mask definition is not found,
 * then deliver -1.
 * if the mask definition has less frames than master_frame_nr, then deliver the
 * last available frame as mask.
 * return the image id.
 */
static gint32
p_mask_fetcher(GapStoryRenderVidHandle *vidhand
   , const char *mask_name
   , gint32 master_frame_nr
   , gint32 mask_width
   , gint32 mask_height
   , gint32 *layer_id_ptr           /* OUT: Id of the only layer in the composite image */
   , gboolean *was_last_maskframe   /* OUT: true if this was the last maskframe */
   )
{
  GapStoryRenderMaskDefElem *maskdef_elem;
  gint32 image_id;
 
  *was_last_maskframe = FALSE;
  image_id = -1;
  
    
  maskdef_elem = p_find_maskdef_by_name(vidhand, mask_name);

  if(maskdef_elem)
  {
    gint32 l_framenr;

    /* limit access to last available frame */
    l_framenr = MIN(master_frame_nr, maskdef_elem->frame_count);


     if(gap_debug)
     {
       printf("\n############# MASK start FETCH ##########\n");
       printf("MASK relevant framenr:%d\n"
            , (int)l_framenr
            );
       gap_story_render_debug_print_maskdef_elem(maskdef_elem, -7);
     }
     
    /* the composite image fecther already converts to gray when called
     * with a mask videohandle (marked with is_mask_handle flag)
     */
    image_id = gap_story_render_fetch_composite_image(maskdef_elem->mask_vidhand
                  , l_framenr        /* starts at 1 */
                  , mask_width       /* desired  Width in pixels */
                  , mask_height      /* desired  Height in pixels */
                  , NULL             /* NULL if no filtermacro is used */
                  , layer_id_ptr     /* OUT: Id of the only layer in the composite image */
                 );

    if(gap_debug)
    {
      printf("\n.........#### MASK end FETCH ####......\n");
    }
    
    
    *layer_id_ptr = gap_layer_flip(*layer_id_ptr, maskdef_elem->flip_request);

    if(gimp_drawable_has_alpha(*layer_id_ptr))
    {
      *layer_id_ptr = gimp_image_flatten(image_id);
    }
    
    if(gap_debug)
    {
      printf("p_mask_fetcher: flip_request:%d\n"
        ,(int)maskdef_elem->flip_request
        );
    }

    if (l_framenr == maskdef_elem->frame_count)
    {
      *was_last_maskframe = TRUE;
    }

  }

  return(image_id);
}  /* end p_mask_fetcher */



/* ----------------------------------------------------
 * p_fetch_and_add_layermask
 * ----------------------------------------------------
 */
static void
p_fetch_and_add_layermask(GapStoryRenderVidHandle *vidhand
                  , GapStoryRenderFrameRangeElem *frn_elem
                  , gint32 local_stepcount
                  , gint32 image_id
                  , gint32 layer_id
                  )
{
  gint32  l_tmp_mask_image_id;
  gint32  l_tmp_mask_layer_id;
  gint32  l_master_framenr;
  gdouble l_framenr;
  gboolean l_found_in_cache;
  gboolean l_was_last_maskframe;
  
  /* both local_stepcount and mask_framecount start with 0 for the 1st element */
  l_framenr = frn_elem->mask_stepsize * (gdouble)(frn_elem->mask_framecount + local_stepcount);
  l_master_framenr = 1 + (gint32)(l_framenr);

  if(gap_debug)
  {
    printf("\n============--------------====\n");
    printf("p_fetch_and_add_layermask: local_stepcount: %d master_framenr:%d\n"
          ,(int)local_stepcount
          ,(int)l_master_framenr
          );
    gap_story_render_debug_print_frame_elem(frn_elem, -5);
  }


  l_found_in_cache = FALSE;
  
  // l_tmp_mask_image_id = TODO lookup in the cache ################
 
  if(l_found_in_cache)
  {
     if(gap_debug)
     {
       printf("FOUND MASK in cache: mask_name:%s master_framenr:%d\n"
              ,frn_elem->mask_name
              ,(int)l_master_framenr
              );
     }
  }
  else
  {
    l_tmp_mask_image_id = p_mask_fetcher(vidhand
                              , frn_elem->mask_name
                              , l_master_framenr
                              , gimp_drawable_width(layer_id)
                              , gimp_drawable_height(layer_id)
                              ,&l_tmp_mask_layer_id
                              ,&l_was_last_maskframe
                              );
  }
  
  if(gap_debug)
  {
    printf("MASK image_id: %d l_tmp_mask_layer_id:%d\n"
           ,(int)l_tmp_mask_image_id
           ,(int)l_tmp_mask_layer_id
           );
  }
  
  if(l_tmp_mask_image_id >= 0)
  {
     gint32 l_new_layer_mask_id;
     

     if(1==0)
     {
       p_debug_dup_image(l_tmp_mask_image_id);
     }


     /* add aplha channel if necessary
      * (this is required to allow adding the layermask
      */
     if(!gimp_drawable_has_alpha(layer_id))
     {
       gimp_layer_add_alpha(layer_id);
     }
     l_new_layer_mask_id = gimp_layer_create_mask(layer_id, GIMP_ADD_WHITE_MASK);
     gimp_layer_add_mask(layer_id, l_new_layer_mask_id);
     
     
     /* overwrite the white layer mask with the fetched mask */
     gap_layer_copy_content(l_new_layer_mask_id   /* dst_drawable_id */
                           ,l_tmp_mask_layer_id     /* src_drawable_id */
                           );
     

     if(!l_found_in_cache)
     {
       // TODO: decide if l_tmp_mask_image_id should be stored in cache or to delete immediate.
       // store if: 
       //  - there are more than one references
       //  - if mask stepsize < 1.0
       //  - the last frame of the mask sequence  (l_framenr == maskdef_elem->frame_count)
       //     (that has to be repeated for all remaining frame in the clip)
       
       // if((frn_elem->mask_stepsize < 1.0)
       // || (l_was_last_maskframe)
       // )
       


       gap_image_delete_immediate(l_tmp_mask_image_id);
     }
  }                          
  
}  /* end p_fetch_and_add_layermask */


/* ----------------------------------------------------
 * p_open_video_handle_private
 * ----------------------------------------------------
 * this procedure builds a framerange list from
 * the given storyboard file.
 * if NULL is passed as storyboard_file
 * the list is built with just one entry.
 * from basename and ext parameters.
 *
 * return framerange list
 */
static GapStoryRenderVidHandle *
p_open_video_handle_private(    gboolean ignore_audio
                      , gboolean ignore_video
		      , gboolean create_audio_tmp_files
                      , gdouble  *progress_ptr
                      , char *status_msg
                      , gint32 status_msg_len
                      , const char *storyboard_file
                      , const char *basename
                      , const char *ext
                      , gint32  frame_from
                      , gint32  frame_to
                      , gint32 *frame_count   /* output total frame_count , or 0 on failure */
                      , gboolean do_gimp_progress
		      , GapLibTypeInputRange input_mode
		      , const char *imagename
                      , const char *preferred_decoder
                      , gint32 seltrack
                      , gint32 exact_seek
                      , gdouble delace
                      , gboolean compensate_framerange
                      , GapStoryBoard *stb_mem_ptr
                      )
{
  GapStoryRenderVidHandle *vidhand;
  GapStoryRenderFrameRangeElem *frn_elem;
  gdouble dummy_progress;

  vidhand = g_malloc0(sizeof(GapStoryRenderVidHandle));

  if(progress_ptr) { vidhand->progress = progress_ptr; }
  else             { vidhand->progress = &dummy_progress; }

  if(status_msg)
  {
    vidhand->status_msg = status_msg;
    vidhand->status_msg_len = status_msg_len;
  }
  else
  {
    vidhand->status_msg = NULL;
    vidhand->status_msg_len = 0;
  }

  vidhand->frn_list = NULL;
  vidhand->preferred_decoder = NULL;
  vidhand->do_gimp_progress = do_gimp_progress;
  *vidhand->progress = 0.0;
  vidhand->sterr = p_new_stb_error();
  vidhand->master_framerate = 25.0;
  vidhand->master_width = 0;
  vidhand->master_height = 0;
  vidhand->master_samplerate = 44100;    /* 44.1 kHZ CD standard Quality */
  vidhand->master_volume     = 1.0;
  vidhand->util_sox          = NULL;     /* use DEFAULT resample program (sox), where needed */
  vidhand->util_sox_options  = NULL;     /* use DEFAULT options */
  vidhand->ignore_audio      = ignore_audio;
  vidhand->ignore_video      = ignore_video;
  vidhand->create_audio_tmp_files = create_audio_tmp_files;

  vidhand->maskdef_elem = NULL;
  vidhand->is_mask_handle = FALSE;

  global_monitor_image_id = -1;
  *frame_count = 0;

  if((storyboard_file) && (input_mode == GAP_RNGTYPE_STORYBOARD))
  {
    if(*storyboard_file != '\0')
    {
      vidhand->frn_list = p_framerange_list_from_storyboard(storyboard_file
                                                  , frame_count
                                                  , vidhand
                                                  , stb_mem_ptr);
    }
  }

  if((vidhand->frn_list == NULL)
  && (input_mode == GAP_RNGTYPE_LAYER)
  && (imagename))
  {
      gint32 l_from;
      gint32 l_to;
      
      l_from = frame_from;
      l_to = frame_to;
      if(compensate_framerange)
      {
        /* layerindex starts with 0, but master_index should start with 1
         * increment by 1 to compensate. (only needed for single multilayer image encoding)
         */
        l_from = 1;
        l_to = 1+ MAX(frame_to,   frame_from);
      
      }
      
      /* add element for animimage (one multilayer image) */
      frn_elem = p_new_framerange_element(GAP_FRN_ANIMIMAGE
                                         , 1           /* track */
                                         , imagename
                                         , NULL
                                         , l_from
                                         , l_to
                                         , NULL       /* storyboard_file */
                                         , NULL       /* preferred_decoder */
                                         , NULL       /* filtermacro_file */
                                         , NULL       /* frn_list */
                                         , vidhand->sterr
                                         , 1          /* seltrack */
                                         , 0              /* exact_seek*/
                                         , 0.0            /* delace */
					 , 1.0            /* step_density */
                                         , GAP_STB_FLIP_NONE    /* flip_request */
                                         , NULL                 /* mask_name */
                                         , 1.0                  /* mask_stepsize */
                                         , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                         , TRUE                 /* mask_disable */
                                         );
      if(frn_elem)
      {
        *frame_count = frn_elem->frames_to_handle;
      }

      if(compensate_framerange)
      {
        /* add a layer 0 (as separate 1.st listelement)
         * to compensate framenumbers if the range does not start with 1
         */
        vidhand->frn_list = p_new_framerange_element(GAP_FRN_ANIMIMAGE
                                         , 1           /* track */
                                         , imagename
                                         , NULL
                                         , 1          /* from */
                                         , 1          /* to */
                                         , NULL       /* storyboard_file */
                                         , NULL       /* preferred_decoder */
                                         , NULL       /* filtermacro_file */
                                         , NULL       /* frn_list */
                                         , vidhand->sterr
                                         , 1              /* seltrack */
                                         , 0              /* exact_seek*/
                                         , 0.0            /* delace */
					 , 1.0            /* step_density */
                                         , GAP_STB_FLIP_NONE    /* flip_request */
                                         , NULL                 /* mask_name */
                                         , 1.0                  /* mask_stepsize */
                                         , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                         , TRUE                 /* mask_disable */
                                         );
        vidhand->frn_list->frames_to_handle = l_from -1;
        vidhand->frn_list->next = frn_elem;
        if(gap_debug)
        {
          printf("***************************\n");        
          printf("COMPENSATE LAYERS (ANIMIMAGE):\n");
          gap_story_render_debug_print_framerange_list(vidhand->frn_list , -1);       
          printf("***************************\n");
        }
      }
      else
      {
        vidhand->frn_list = frn_elem;
      }
  }
  
  if((vidhand->frn_list == NULL)
  && (basename)
  && (ext))
  {
    gint32 l_from;
    gint32 l_to;

    l_from = frame_from;
    l_to = frame_to;
    if(compensate_framerange)
    {
      /* layerindex starts with 0, but master_index should start with 1
       * increment by 1 to compensate. (only needed for single multilayer image encoding)
       */
      l_from = MIN(frame_from, frame_to);
      l_to = MAX(frame_to,   frame_from);
    }
    
    if(input_mode == GAP_RNGTYPE_FRAMES)
    {
      /* element for framerange */
      frn_elem = p_new_framerange_element(GAP_FRN_FRAMES
                                         , 1           /* track */
                                         , basename
                                         , ext
                                         , l_from
                                         , l_to
                                         , NULL       /* storyboard_file */
                                         , NULL       /* preferred_decoder */
                                         , NULL       /* filtermacro_file */
                                         , NULL       /* frn_list */
                                         , vidhand->sterr
                                         , 1          /* seltrack */
                                         , 0              /* exact_seek*/
                                         , 0.0            /* delace */
					 , 1.0            /* step_density */
                                         , GAP_STB_FLIP_NONE    /* flip_request */
                                         , NULL                 /* mask_name */
                                         , 1.0                  /* mask_stepsize */
                                         , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                         , TRUE                 /* mask_disable */
                                         );
      if(frn_elem) *frame_count = frn_elem->frames_to_handle;


      if(compensate_framerange)
      {
        /* add a SILENCE dummy (as 1.st listelement)
         * to compensate framenumbers if the range does not start with 1
         */
        vidhand->frn_list = p_new_framerange_element(GAP_FRN_SILENCE
                                           , 1               /* track */
                                           , NULL
                                           , NULL
                                           , 0               /* frame_from */
                                           , l_from -1       /* frame_to */
                                           , NULL            /* storyboard_file */
                                           , NULL            /* preferred_decoder */
                                           , NULL            /* filtermacro_file */
                                           , NULL            /* frn_list */
                                           , vidhand->sterr
                                           , 1               /* seltrack */
                                           , 0               /* exact_seek*/
                                           , 0.0             /* delace */
					   , 1.0             /* step_density */
                                           , GAP_STB_FLIP_NONE    /* flip_request */
                                           , NULL                 /* mask_name */
                                           , 1.0                  /* mask_stepsize */
                                           , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                           , TRUE                 /* mask_disable */
                                           );
        vidhand->frn_list->frames_to_handle = l_from -1;
        vidhand->frn_list->next = frn_elem;
        if(gap_debug)
        {
          printf("***************************\n");        
          printf("COMPENSATE FRAMES:\n");
          gap_story_render_debug_print_framerange_list(vidhand->frn_list , -1);       
          printf("***************************\n");
        }
      }
      else
      {
        vidhand->frn_list = frn_elem;
      }
    }
  }


  if((vidhand->frn_list == NULL)
  && (input_mode == GAP_RNGTYPE_IMAGE)
  && (imagename))
  {
      /* add element for single image 
       * (typical used only for mask definitions)
       */
      frn_elem = p_new_framerange_element(GAP_FRN_IMAGE
                                         , 1           /* track */
                                         , imagename
                                         , NULL
                                         , 1          /* frame_from */
                                         , 1          /* frame_to */
                                         , NULL       /* storyboard_file */
                                         , NULL       /* preferred_decoder */
                                         , NULL       /* filtermacro_file */
                                         , NULL       /* frn_list */
                                         , vidhand->sterr
                                         , 1          /* seltrack */
                                         , 0              /* exact_seek*/
                                         , 0.0            /* delace */
					 , 1.0            /* step_density */
                                         , GAP_STB_FLIP_NONE    /* flip_request */
                                         , NULL                 /* mask_name */
                                         , 1.0                  /* mask_stepsize */
                                         , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                         , TRUE                 /* mask_disable */
                                         );
      if(frn_elem)
      {
        *frame_count = frn_elem->frames_to_handle;
      }
      vidhand->frn_list = frn_elem;
  }
  
  
  if((vidhand->frn_list == NULL)
  && (input_mode == GAP_RNGTYPE_MOVIE)
  && (imagename))
  {
      /* add element for single movie input
       * (typical used only for mask definitions)
       */
      frn_elem = p_new_framerange_element(GAP_FRN_MOVIE
                                         , 1           /* track */
                                         , imagename
                                         , NULL
                                         , frame_from
                                         , frame_to
                                         , NULL       /* storyboard_file */
                                         , preferred_decoder
                                         , NULL       /* filtermacro_file */
                                         , NULL       /* frn_list */
                                         , vidhand->sterr
                                         , seltrack
                                         , exact_seek
                                         , delace
					 , 1.0            /* step_density */
                                         , GAP_STB_FLIP_NONE    /* flip_request */
                                         , NULL                 /* mask_name */
                                         , 1.0                  /* mask_stepsize */
                                         , GAP_MSK_ANCHOR_CLIP  /* mask_anchor */
                                         , TRUE                 /* mask_disable */
                                         );
      if(frn_elem)
      {
        *frame_count = frn_elem->frames_to_handle;
      }
      vidhand->frn_list = frn_elem;
  }
  
  /* p_free_stb_error(vidhand->sterr); */

  if(gap_debug)
  {
    printf("\n\np_open_video_handle_private: END\n\n");
    gap_story_render_debug_print_framerange_list(vidhand->frn_list, -1);
  }
  return(vidhand);

} /* end p_open_video_handle_private */


/* ----------------------------------------------------
 * gap_story_render_open_extended_video_handle
 * ----------------------------------------------------
 * this procedure builds a framerange list from
 * the given storyboard file.
 * if NULL is passed as storyboard_file
 * the list is built with just one entry.
 * from basename and ext parameters.
 *
 * return framerange list
 */
GapStoryRenderVidHandle *
gap_story_render_open_extended_video_handle(    gboolean ignore_audio
                      , gboolean ignore_video
		      , gboolean create_audio_tmp_files
                      , gdouble  *progress_ptr
                      , char *status_msg
                      , gint32 status_msg_len
		      , GapLibTypeInputRange input_mode
		      , const char *imagename
                      , const char *storyboard_file
                      , const char *basename
                      , const char *ext
                      , gint32  frame_from
                      , gint32  frame_to
                      , gint32 *frame_count   /* output total frame_count , or 0 on failure */
                      )
{
  return(p_open_video_handle_private( ignore_audio  /* ignore_audio */
                            , ignore_video          /* dont ignore_video */
			    , create_audio_tmp_files
                            , progress_ptr          /* progress_ptr */
                            , status_msg            /* status_msg */
                            , status_msg_len        /* status_msg_len */
                            ,storyboard_file
                            ,basename
                            ,ext
                            ,frame_from
                            ,frame_to
                            ,frame_count
                            ,FALSE          /* DONT do_gimp_progress */
			    ,input_mode
			    ,imagename
                            ,NULL           /* preferred_decoder */
                            ,1              /* seltrack */
                            ,0              /* exact_seek */
                            ,0.0            /* delace */
                            ,TRUE           /* compensate_framerange */
                            ,NULL           /* stb_mem_ptr */
                            )
         );

} /* end gap_story_render_open_extended_video_handle */

/* ----------------------------------------------------
 * gap_story_render_open_vid_handle_from_stb
 * ----------------------------------------------------
 * this procedure builds a framerange list from
 * the given storyboard in MEMORY.
 *
 * this wrapper to p_open_video_handle
 * ignores AUDIO informations in the storyboard file
 * (Typically the Player uses this variant
 *  for playback of composite storyboard video)
 *
 * return the video handle
 */
GapStoryRenderVidHandle *
gap_story_render_open_vid_handle_from_stb(GapStoryBoard *stb_mem_ptr
                          ,gint32 *frame_count   /* output total frame_count , or 0 on failure */
                          )
{
  GapStoryRenderVidHandle *l_vidhand;

  l_vidhand = NULL;
  if(stb_mem_ptr)
  {
    l_vidhand = p_open_video_handle_private( TRUE         /* ignore_audio */
                            , FALSE        /* dont ignore_video */
                            , FALSE        /* create_audio_tmp_files */
                            , NULL         /* progress_ptr */
                            , NULL         /* status_msg */
                            , 0            /* status_msg_len */
                            ,stb_mem_ptr->storyboardfile
                            , NULL         /* basename */
                            , NULL         /* ext */
                            ,1             /* frame_from (not relevant) */
                            ,1             /* frame_to (not relevant)  */
                            ,frame_count
                            ,FALSE         /* do_gimp_progress */
			    ,GAP_RNGTYPE_STORYBOARD         /* input_mode */
			    ,NULL           /* imagename */
                            ,NULL           /* preferred_decoder */
                            ,1              /* seltrack */                            
                            ,0              /* exact_seek */
                            ,0.0            /* delace */
                            ,TRUE           /* compensate_framerange */
                            ,stb_mem_ptr    /* stb_mem_ptr */
                            );
  }

  return(l_vidhand);
}  /* end gap_story_render_open_vid_handle_from_stb */

/* ----------------------------------------------------
 * gap_story_render_open_vid_handle
 * ----------------------------------------------------
 * this procedure builds a framerange list from
 * the given storyboard file.
 * if NULL is passed as storyboard_file
 * the list is built with just one entry
 * from basename and ext parameters.
 *
 * this wrapper to p_open_video_handle
 * ignores AUDIO informations in the storyboard file
 * (The encoders use this variant
 *  because the common GUI usually creates
 *  the composite audio track, and passes
 *  the resulting WAV file ready to use)
 *
 * return the video handle
 */
GapStoryRenderVidHandle *
gap_story_render_open_vid_handle(GapLibTypeInputRange input_mode
                      , gint32 image_id
		      , const char *storyboard_file
                      , const char *basename
                      , const char *ext
                      , gint32  frame_from
                      , gint32  frame_to
                      , gint32 *frame_count   /* output total frame_count , or 0 on failure */
                      )
{
  GapStoryRenderVidHandle *l_vidhand;
  char *imagename;

  imagename = NULL;
  if(image_id >= 0)
  {
    imagename = gimp_image_get_filename(image_id);
  }
  l_vidhand = p_open_video_handle_private( TRUE         /* ignore_audio */
                            , FALSE        /* dont ignore_video */
                            , FALSE        /* create_audio_tmp_files */
                            , NULL         /* progress_ptr */
                            , NULL         /* status_msg */
                            , 0            /* status_msg_len */
                            ,storyboard_file
                            ,basename
                            ,ext
                            ,frame_from
                            ,frame_to
                            ,frame_count
                            ,TRUE          /* do_gimp_progress */
			    ,input_mode
			    ,imagename
                            ,NULL           /* preferred_decoder */
                            ,1              /* seltrack */                            
                            ,0              /* exact_seek */
                            ,0.0            /* delace */
                            ,TRUE           /* compensate_framerange */
                            ,NULL           /* stb_mem_ptr */
                            );

  if(imagename)
  {
    g_free(imagename);
  }
  return(l_vidhand);
}


/* ----------------------------------------------------
 * p_exec_filtermacro
 * ----------------------------------------------------
 * - execute the (optional) filtermacro_file if not NULL
 *   (filtermacro_file is a set of one or more gimp_filter procedures
 *    with predefined parameter values)
 */
static gint32
p_exec_filtermacro(gint32 image_id, gint32 layer_id, const char *filtermacro_file)
{
  GimpParam* l_params;
  gint   l_retvals;
  gint32 l_rc_layer_id;
  gint          l_nlayers;
  gint32       *l_layers_list;

  l_rc_layer_id = layer_id;
  if (filtermacro_file)
  {
    if(*filtermacro_file != '\0')
    {
       if(gap_debug) printf("DEBUG: before execute filtermacro_file:%s image_id:%d layer_id:%d\n"
                              , filtermacro_file
                              , (int)image_id
                              , (int)layer_id
                              );

       /* execute GAP Filtermacro_file */
       l_params = gimp_run_procedure ("plug_in_filter_macro",
                     &l_retvals,
                     GIMP_PDB_INT32,    GIMP_RUN_NONINTERACTIVE,
                     GIMP_PDB_IMAGE,    image_id,
                     GIMP_PDB_DRAWABLE, layer_id,
                     GIMP_PDB_STRING,   filtermacro_file,
                     GIMP_PDB_END);

       if(l_params[0].data.d_status != GIMP_PDB_SUCCESS)
       {
         printf("ERROR: filtermacro_file:%s failed\n", filtermacro_file);
         l_rc_layer_id = -1;
       }
       g_free(l_params);

       l_layers_list = gimp_image_get_layers(image_id, &l_nlayers);
       if(l_layers_list != NULL)
       {
         g_free (l_layers_list);
       }
       if(l_nlayers > 1 )
       {
         /* merge visible layers (reduce to single layer) */
         l_rc_layer_id = gap_image_merge_visible_layers(image_id, GIMP_CLIP_TO_IMAGE);
       }

    }
  }
  return(l_rc_layer_id);
} /* end p_exec_filtermacro */


/* ----------------------------------------------------
 * p_transform_and_add_layer
 * ----------------------------------------------------
 * - copy the layer (layer_id) to the composite image
 *   using copy/paste
 * - the source Layer (layer_id) must be part of tmp_image_id
 * - set opacity, scale and move layer_id according to video attributes
 *
 * return the new created layer id in the comp_image_id
 *   (that is already added to the composte image on top of layerstack)
 */
static gint32
p_transform_and_add_layer( gint32 comp_image_id
                         , gint32 tmp_image_id
                         , gint32 layer_id
                         , gboolean keep_proportions
                         , gboolean fit_width
                         , gboolean fit_height
                         , gdouble opacity    /* 0.0 upto 1.0 */
                         , gdouble scale_x    /* 0.0 upto 10.0 where 1.0 = 1:1 */
                         , gdouble scale_y    /* 0.0 upto 10.0 where 1.0 = 1:1 */
                         , gdouble move_x     /* -1.0 upto +1.0 where 0 = no move, -1 is left outside */
                         , gdouble move_y     /* -1.0 upto +1.0 where 0 = no move, -1 is top outside */
                         , char *filtermacro_file
                         , gint32 flip_request
                         , GapStoryRenderFrameRangeElem *frn_elem
                         , GapStoryRenderVidHandle *vidhand
                         , gint32 local_stepcount
                         )
{
  gint32 vid_width;
  gint32 vid_height;
  gint32 l_new_layer_id;
  gint32 l_fsel_layer_id;
  GapStoryCalcAttr  calculate_attributes;
  GapStoryCalcAttr  *calculated;

  if(gap_debug)
  {
    printf("p_transform_and_add_layer: called at layer_id: %d, tmp_image_id:%d\n"
      , (int)layer_id 
      ,(int)tmp_image_id );
  }

  layer_id = gap_layer_flip(layer_id, flip_request);

  /* execute input track specific  filtermacro (optional if supplied) */
  p_exec_filtermacro(tmp_image_id
                    , layer_id
                    , filtermacro_file
                    );

  /* expand layer to tmp image size (before applying any scaling) */
  gimp_layer_resize_to_image_size(layer_id);
  
  vid_width = gimp_image_width(comp_image_id);
  vid_height = gimp_image_height(comp_image_id);
 
  /* calculate scaling, offsets and opacity  according to current attributes */ 
  gap_story_file_calculate_render_attributes(&calculate_attributes
    , vid_width
    , vid_height
    , vid_width
    , vid_height
    , gimp_image_width(tmp_image_id)
    , gimp_image_height(tmp_image_id)
    , keep_proportions
    , fit_width
    , fit_height
    , opacity
    , scale_x
    , scale_y
    , move_x
    , move_y
    );

  calculated = &calculate_attributes;


  /* check size and scale source layer_id to calculated size
   */
  if ((gimp_image_width(tmp_image_id) != calculated->width)
  ||  (gimp_image_height(tmp_image_id) != calculated->height) )
  {
    if(gap_debug) printf("DEBUG: p_transform_and_add_layer scaling layer from %dx%d to %dx%d\n"
                            , (int)gimp_image_width(tmp_image_id)
                            , (int)gimp_image_height(tmp_image_id)
                            , (int)calculated->width
                            , (int)calculated->height
                            );

    gimp_layer_scale(layer_id, calculated->width, calculated->height
                    , FALSE  /* FALSE: centered at image TRUE: centered local on layer */
                    );

  }


  /* add a new layer to composite image */
  l_new_layer_id = gimp_layer_new(comp_image_id
                              , "pasted_track"
                              , vid_width
                              , vid_height
                              , GIMP_RGBA_IMAGE
                              , 0.0         /* Opacity full transparent */
                              ,GIMP_NORMAL_MODE);
  gimp_image_add_layer(comp_image_id, l_new_layer_id, 0);
  gap_layer_clear_to_color(l_new_layer_id, 0.0, 0.0, 0.0, 0.0);

  if((frn_elem->mask_name != NULL)
  && (frn_elem->mask_anchor == GAP_MSK_ANCHOR_CLIP))
  {
     p_fetch_and_add_layermask(vidhand
                  , frn_elem
                  , local_stepcount
                  , tmp_image_id
                  , layer_id
                  );
     /* apply the mask (necessary because the following copy with this layer
      * as source would ignore the layer mask)
      */             
     gimp_layer_remove_mask(layer_id, GIMP_MASK_APPLY);

  }

  /* copy from tmp_image and paste to composite_image
   * force copying of the complete layer by clearing the selection 
   */
  gimp_selection_none(tmp_image_id);
  gimp_edit_copy(layer_id);
  l_fsel_layer_id = gimp_edit_paste(l_new_layer_id, FALSE);  /* FALSE paste clear selection */

  gimp_layer_set_offsets(l_fsel_layer_id
                        , calculated->x_offs
                        , calculated->y_offs
                        );

  gimp_floating_sel_anchor(l_fsel_layer_id);
  
  if((frn_elem->mask_name != NULL)
  && (frn_elem->mask_anchor == GAP_MSK_ANCHOR_MASTER))
  {
     p_fetch_and_add_layermask(vidhand
                  , frn_elem
                  , local_stepcount
                  , comp_image_id
                  , l_new_layer_id
                  );

  }

  gimp_layer_set_opacity(l_new_layer_id, calculated->opacity);

  return(l_new_layer_id);
}   /* end p_transform_and_add_layer */





/* ----------------------------------------------------
 * p_create_unicolor_image
 * ----------------------------------------------------
 * - create a new image with one black filled layer
 *   (both have the requested size)
 *
 * return the new created image_id
 *   and the layer_id of the black_layer
 */
static gint32
p_create_unicolor_image(gint32 *layer_id, gint32 width , gint32 height
                       , gdouble r_f, gdouble g_f, gdouble b_f, gdouble a_f)
{
  gint32 l_empty_layer_id;
  gint32 l_image_id;

  *layer_id = -1;
  l_image_id = gimp_image_new(width, height, GIMP_RGB);
  if(l_image_id >= 0)
  {
    l_empty_layer_id = gimp_layer_new(l_image_id, "black_background",
                          width, height,
                          GIMP_RGBA_IMAGE,
                          100.0,     /* Opacity full opaque */
                          GIMP_NORMAL_MODE);
    gimp_image_add_layer(l_image_id, l_empty_layer_id, 0);

    /* clear layer to unique color */
    gap_layer_clear_to_color(l_empty_layer_id, r_f, g_f, b_f, a_f);

    *layer_id = l_empty_layer_id;
  }
  return(l_image_id);
}       /* end p_create_unicolor_image */

/* ----------------------------------------------------
 * p_prepare_RGB_image
 * ----------------------------------------------------
 * prepare image for encoding
 * - clear undo stack
 * - convert to RGB
 * - merge all visible layer to one layer that
 *   fits the image size.
 *
 * return the resulting layer_id.
 */
static gint32
p_prepare_RGB_image(gint32 image_id)
{
  gint          l_nlayers;
  gint32       *l_layers_list;
  gint32 l_layer_id;

  l_layer_id = -1;
 /* dont waste time and memory for undo in noninteracive processing
  * of the frames
  */
  /*  gimp_image_undo_enable(image_id); */ /* clear undo stack */
  /* no more gimp_image_undo_enable, because this results in Warnings since gimp-2.1.6
   * Gimp-Core-CRITICAL **: file gimpimage.c: line 1708 (gimp_image_undo_thaw): assertion `gimage->undo_freeze_count > 0' failed
   */
  gimp_image_undo_disable(image_id); /*  NO Undo */

  l_layers_list = gimp_image_get_layers(image_id, &l_nlayers);
  if(l_layers_list != NULL)
  {
    l_layer_id = l_layers_list[0];
    g_free (l_layers_list);
  }

  if(l_nlayers > 1 )
  {
     if(gap_debug) printf("DEBUG: p_prepare_image merge layers tmp image\n");

     /* merge visible layers (reduce to single layer) */
     l_layer_id = gap_image_merge_visible_layers(image_id, GIMP_CLIP_TO_IMAGE);
  }

  /* convert TO RGB if needed */
  if(gimp_image_base_type(image_id) != GIMP_RGB)
  {
     gimp_image_convert_rgb(image_id);
  }

  if(l_layer_id >= 0)
  {
    gimp_layer_resize_to_image_size(l_layer_id);
  }

  return(l_layer_id);
} /* end p_prepare_RGB_image */

/* ----------------------------------------------------
 * p_try_to_steal_gvahand
 * ----------------------------------------------------
 * try to steal an alread open GVA handle for video read from another
 * element.
 * conditions: must use same videofile, and exact_seek mode
 * but steal only handles that are not in current access
 * (where the last accessed master_frame_nr is lower
 * than the current one)
 */
static t_GVA_Handle *
p_try_to_steal_gvahand(GapStoryRenderVidHandle *vidhand
                      , gint32 master_frame_nr
                      , char *basename             /* the videofile name */
                      , gint32 exact_seek
                      )
{
  GapStoryRenderFrameRangeElem *frn_elem;
  t_GVA_Handle *gvahand;

  for (frn_elem = vidhand->frn_list; frn_elem != NULL; frn_elem = (GapStoryRenderFrameRangeElem *)frn_elem->next)
  {
    if((frn_elem->exact_seek == exact_seek)
    && (frn_elem->last_master_frame_access < master_frame_nr)
    && (frn_elem->gvahand != NULL))
    {
      if(strcmp(frn_elem->basename, basename) == 0)
      {
         if(gap_debug) printf("(RE)using an already open GVA handle for video read access %s\n", frn_elem->basename);
         gvahand = frn_elem->gvahand;
         frn_elem->gvahand = NULL;   /* steal from this element */
         return(gvahand);
      }
    }
  }
  return(NULL);  /* nothing found to steal from, return NULL */

} /* end p_try_to_steal_gvahand */




/* ------------------------------------
 * gap_story_render_calc_audio_playtime
 * ------------------------------------
 * - check all audio tracks for audio playtime
 *   set *aud_total_sec to the playtime of the
 *   logest audio track playtime.
 */
void
gap_story_render_calc_audio_playtime(GapStoryRenderVidHandle *vidhand, gdouble *aud_total_sec)
{
  gap_story_render_audio_calculate_playtime(vidhand, aud_total_sec);
}  /* gap_story_render_calc_audio_playtime */


/* -------------------------------------------
 * gap_story_render_create_composite_audiofile
 * -------------------------------------------
 */
gboolean
gap_story_render_create_composite_audiofile(GapStoryRenderVidHandle *vidhand
                            , char *comp_audiofile
                            )
{
  return (gap_story_render_audio_create_composite_audiofile(vidhand, comp_audiofile));

}   /* end gap_story_render_create_composite_audiofile */



/* ----------------------------------------------------
 * p_check_chunk_fetch_possible
 * ----------------------------------------------------
 * This procedure checks the preconditions for a possible
 * fetch of already compresses MPEG chunks.
 * - there is only 1 videoinput track at this master_frame_nr
 * - the videoframe must match 1:1 in size
 * - there are no transformations (opacity, offsets ....)
 *
 * return the name of the input videofile if preconditions are OK,
 *        or NULL if not.
 */
static char *
p_check_chunk_fetch_possible(GapStoryRenderVidHandle *vidhand
                    , gint32 master_frame_nr  /* starts at 1 */
                    , gint32  vid_width       /* desired Video Width in pixels */
                    , gint32  vid_height      /* desired Video Height in pixels */
                    , gint32 *video_frame_nr  /* OUT: corresponding frame number in the input video */
		    , GapStoryRenderFrameRangeElem **frn_elem  /* OUT: pointer to relevant frame range element */
                    )
{
  gint    l_track;
  gint32    l_track_min;
  gint32    l_track_max;
  gchar  *l_framename;
  gchar  *l_videofile;
  gdouble l_opacity;
  gdouble l_scale_x;
  gdouble l_scale_y;
  gdouble l_move_x;
  gdouble l_move_y;
  GapStoryRenderFrameRangeElem *l_frn_elem_2;

  gint32        l_localframe_index;
  gint32        l_local_stepcount;
  gboolean      l_keep_proportions;
  gboolean      l_fit_width;
  gboolean      l_fit_height;
  GapStoryRenderFrameType   l_frn_type;
  char            *l_trak_filtermacro_file;
  gdouble l_red_f;
  gdouble l_green_f;
  gdouble l_blue_f;
  gdouble l_alpha_f;


  *video_frame_nr   = -1;
  *frn_elem = NULL;

  l_videofile = NULL;
  
  p_find_min_max_vid_tracknumbers(vidhand->frn_list, &l_track_min, &l_track_max);

  /* findout if there is just one input track from type videofile
   * (that possibly could be fetched as comressed videoframe_chunk
   *  and passed 1:1 to the calling encoder)
   */
  for(l_track = MIN(GAP_STB_MAX_VID_INTERNAL_TRACKS, l_track_max); l_track >= MAX(0, l_track_min); l_track--)
  {
    l_framename = p_fetch_framename(vidhand->frn_list
                 , master_frame_nr /* starts at 1 */
                 , l_track
                 , &l_frn_type
                 , &l_trak_filtermacro_file
                 , &l_localframe_index   /* used for ANIMIMAGE and Videoframe Number, -1 for all other types */
                 , &l_local_stepcount
                 , &l_keep_proportions
                 , &l_fit_width
                 , &l_fit_height
                 , &l_red_f
                 , &l_green_f
                 , &l_blue_f
                 , &l_alpha_f
                 , &l_opacity       /* output opacity 0.0 upto 1.0 */
                 , &l_scale_x       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                 , &l_scale_y       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                 , &l_move_x        /* output -1.0 upto 1.0 where 0.0 is centered */
                 , &l_move_y        /* output -1.0 upto 1.0 where 0.0 is centered */
                 , &l_frn_elem_2    /* output selected to the relevant framerange element */
                 );

     if(gap_debug) printf("l_track:%d  l_frn_type:%d\n", (int)l_track, (int)l_frn_type);


     if((l_framename) || (l_frn_type == GAP_FRN_COLOR))
     {
       if(l_framename)
       {
         if(l_frn_type == GAP_FRN_MOVIE)
         {
           if(l_videofile == NULL)
           {
             /* check for transformations */
             if((l_opacity == 1.0)
             && (l_scale_x == 1.0)
             && (l_scale_y == 1.0)
             && (l_move_x == 0.0)
             && (l_move_y == 0.0)
             && (l_fit_width)
             && (l_fit_height)
             && (!l_keep_proportions)
             && (l_frn_elem_2->flip_request == GAP_STB_FLIP_NONE)
             && (l_frn_elem_2->mask_name == NULL)
             
             
             && (l_trak_filtermacro_file == NULL))
             {
               if(gap_debug) printf("gap_story_render_fetch_composite_image_or_chunk:  video:%s\n", l_framename);
               l_videofile = g_strdup(l_framename);
               *video_frame_nr = l_localframe_index;
               *frn_elem = l_frn_elem_2;
             }
             else
             {
               if(gap_debug) printf("gap_story_render_fetch_composite_image_or_chunk:  there are transformations\n");
               /* there are transformations, cant use compressed frame */
               l_videofile = NULL;
               break;
             }
           }
           else
           {
             if(gap_debug) printf("gap_story_render_fetch_composite_image_or_chunk:  2 or more videotracks found\n");
             l_videofile = NULL;
             break;
           }
         }
         else
         {
             l_videofile = NULL;
             break;
         }

         g_free(l_framename);
       }
       else
       {
             l_videofile = NULL;
             break;
       }
     }
     /* else: (vid track not used) continue  */

  }       /* end for loop over all video tracks */

  return(l_videofile);  
}  /* end p_check_chunk_fetch_possible */


/* ----------------------------------------------------
 * gap_story_render_fetch_composite_image_or_chunk
 * ----------------------------------------------------
 *
 * fetch composite VIDEO Image at a given master_frame_nr
 * within a storyboard framerange list
 *
 * if desired (and possible) try directly fetch the (already compressed) Frame chunk from
 * an input videofile for the master_frame_nr.
 *
 * the compressed fetch depends on following conditions:
 * - dont_recode_flag == TRUE
 * - there is only 1 videoinput track at this master_frame_nr
 * - the videodecoder must support a read_video_chunk procedure
 *   (currently only libmpeg3 has this support
 *    TODO: for future releases should also check for the same vcodec_name)
 * - the videoframe must match 1:1 in size
 * - there are no transformations (opacity, offsets ....)
 * - there are no filtermacros to perform on the fetched frame
 *
 * RETURN TRUE on success, FALSE on ERRORS
 *    if an already compressed video_frame_chunk was fetched then return the size of the chunk
 *        in the *video_frame_chunk_size OUT Parameter.
 *        (both *image_id an *layer_id will deliver -1 in that case)
 *    if a composite image was fetched deliver its id in the *image_id OUT parameter
 *        and the id of the only layer in the *layer_id OUT Parameter
 *        the *force_keyframe OUT parameter tells the calling encoder to write an I-Frame
 *        (*video_frame_chunk_size will deliver 0 in that case)
 */
gboolean
gap_story_render_fetch_composite_image_or_chunk(GapStoryRenderVidHandle *vidhand
                    , gint32 master_frame_nr  /* starts at 1 */
                    , gint32  vid_width       /* desired Video Width in pixels */
                    , gint32  vid_height      /* desired Video Height in pixels */
                    , char *filtermacro_file  /* NULL if no filtermacro is used */
                    , gint32 *layer_id        /* output: Id of the only layer in the composite image */

                    , gint32 *image_id        /* output: Id of the only layer in the composite image */
                    , gboolean dont_recode_flag                /* IN: TRUE try to fetch comressed chunk if possible */
                    , char *vcodec_name                        /* IN: video_codec used in the calling encoder program */
                    , gboolean *force_keyframe                 /* OUT: the calling encoder should encode an I-Frame */
                    , unsigned char *video_frame_chunk_data    /* OUT: */
                    , gint32 *video_frame_chunk_size             /* OUT: */
                    , gint32 video_frame_chunk_maxsize           /* IN: */
                    , gdouble master_framerate
                    , gint32  max_master_frame_nr   /* the number of frames that will be encode in total */
                 )
{
#define GAP_MPEG_ASSUMED_REFERENCE_DISTANCE 3
  static gint32     last_video_frame_nr = -1;
  static char      *last_videofile = NULL;
  static gboolean   last_fetch_was_compressed_chunk = FALSE;
  static gboolean   last_intra_frame_fetched = FALSE;

  gchar  *l_framename;
  gchar  *l_videofile_name;
  gchar  *l_videofile;
  GapStoryRenderFrameRangeElem *l_frn_elem;
  GapStoryRenderFrameRangeElem *l_frn_elem_2;

  gint32        l_video_frame_nr;


  *image_id         = -1;
  *layer_id         = -1;
  *force_keyframe   = FALSE;
  l_frn_elem        = NULL;
  *video_frame_chunk_size = 0;

  if(gap_debug)printf("gap_story_render_fetch_composite_image_or_chunk START  master_frame_nr:%d  %dx%d dont_recode:%d\n"
                       , (int)master_frame_nr
                       , (int)vid_width
                       , (int)vid_height
                       , (int)dont_recode_flag
                       );

  l_videofile = NULL;     /* NULL: also used as flag for "MUST fetch regular uncompressed frame" */
  l_videofile_name = NULL;
  l_framename = NULL;
  l_video_frame_nr = 1;

  if(filtermacro_file)
  {
     if(*filtermacro_file != '\0')
     {
       dont_recode_flag = FALSE;  /* if a filtermacro_file used we must force recode */
     }
  }

  /* first check if recode is forced by the calling program */
  if (dont_recode_flag)
  {
    l_videofile = p_check_chunk_fetch_possible(vidhand
                      , master_frame_nr
                      , vid_width 
                      , vid_height
                      , &l_video_frame_nr
		      , &l_frn_elem
                      );
    if(l_videofile)
    {
      l_videofile_name = g_strdup(l_videofile);
    }


    if((l_videofile) && (l_frn_elem))
    {
      if(gap_debug) printf("gap_story_render_fetch_composite_image_or_chunk: ATTEMPT access l_videofile :%s \n", l_videofile);

       /* check if we can FETCH compressed video chunk */
      if(l_frn_elem->gvahand == NULL)
      {
         /* before we open a new GVA videohandle, lets check
          * if another element has already opened this videofile,
          * and reuse the already open gvahand handle if possible
          */
         l_frn_elem->gvahand = p_try_to_steal_gvahand(vidhand
                                                     , master_frame_nr
                                                     , l_frn_elem->basename
                                                     , l_frn_elem->exact_seek
                                                     );
         if(l_frn_elem->gvahand == NULL)
         {
           if(vidhand->preferred_decoder)
           {
             l_frn_elem->gvahand = GVA_open_read_pref(l_videofile
                                    , l_frn_elem->seltrack
                                    , 1 /* aud_track */
                                    , vidhand->preferred_decoder
                                    , FALSE  /* use MMX if available (disable_mmx == FALSE) */
                                    );
           }
           else
           {
             l_frn_elem->gvahand = GVA_open_read(l_videofile
                                               ,l_frn_elem->seltrack
                                               ,1 /* aud_track */
                                               );
           }
           if(l_frn_elem->gvahand)
           {
             GVA_set_fcache_size(l_frn_elem->gvahand, GAP_STB_RENDER_GVA_FRAMES_TO_KEEP_CACHED);

             l_frn_elem->gvahand->do_gimp_progress = vidhand->do_gimp_progress;
             if(l_frn_elem->exact_seek == 1)
             {
               /* configure the GVA Procedures for exact (but slow) seek emulaion */
               l_frn_elem->gvahand->emulate_seek = TRUE;
             }
           }
         }
      }


      if(l_frn_elem->gvahand)
      {
        /* check if framesize matches 1:1 to output video size
         * and if the videodecoder does support a read procedure for compressed vodeo chunks
         * TODO: should also check for compatible vcodec_name
	 *       (cannot check that, because libmpeg3 does not deliver vcodec_name information
	 *        and there is no implementation to fetch uncompressed chunks in other decoders)
         */
        if((l_frn_elem->gvahand->width != vid_width)
        || (l_frn_elem->gvahand->height != vid_height)
        || (GVA_has_video_chunk_proc(l_frn_elem->gvahand) != TRUE) )
        {
          l_videofile = NULL;
        }
        else
        {
          t_GVA_RetCode  l_fcr;

          if(gap_debug) printf("gap_story_render_fetch_composite_image_or_chunk:  performing CHUNK fetch\n");

          /* FETCH compressed video chunk */
          l_fcr = GVA_get_video_chunk(l_frn_elem->gvahand
                                  , l_video_frame_nr
                                  , video_frame_chunk_data
                                  , video_frame_chunk_size
                                  , video_frame_chunk_maxsize
                                  );

          if(gap_debug) printf("gap_story_render_fetch_composite_image_or_chunk:  AFTER CHUNK fetch max:%d chunk_data:%d  chunk_size:%d\n"
                        ,(int)video_frame_chunk_maxsize
                        ,(int)video_frame_chunk_data
                        ,(int)*video_frame_chunk_size
                        );
          if(l_videofile_name)
          {
            g_free(l_videofile_name);
	    l_videofile_name = NULL;
          }

          if(l_fcr == GVA_RET_OK)
          {
	    gint l_frame_type;

	    l_frame_type = GVA_util_check_mpg_frame_type(video_frame_chunk_data
	                                                ,*video_frame_chunk_size
							);
	    GVA_util_fix_mpg_timecode(video_frame_chunk_data
	                             ,*video_frame_chunk_size
				     ,master_framerate
				     ,master_frame_nr
				     );			
            if ((1==0)
	    &&  (master_frame_nr < 10))  /* debug code: dump first 9 video chunks to file(s) */
            {
               FILE *fp;
               char *fname;

               fname = g_strdup_printf("zz_chunk_data_%06d.dmp", (int)l_video_frame_nr);
               fp = g_fopen(fname, "wb");
               if(fp)
               {
                  fwrite(video_frame_chunk_data, *video_frame_chunk_size, 1, fp);
                  fclose(fp);
               }

               g_free(fname);
            }

	    if (l_frame_type == GVA_MPGFRAME_I_TYPE)
	    {
	      /* intra frame has no dependencies to other frames
	       * can use that frame type at any place in the stream 
	       */
              last_video_frame_nr = l_video_frame_nr;
              last_intra_frame_fetched = TRUE;
	      if(last_videofile)
	      {
		g_free(last_videofile);
	      }
	      last_videofile = g_strdup(l_videofile);
	      last_fetch_was_compressed_chunk = TRUE;
	      
	      if(gap_debug)
	      {
	        printf("\nReuse I-FRAME at %06d,", (int)master_frame_nr);
	      }
              return(TRUE);
	    }

	    if ((l_frame_type == GVA_MPGFRAME_P_TYPE)
	    &&  (1==1))
	    {
	      /* predicted frame has dependencies to the previous intra frame
	       * can use that frame if fetch sequence contains previous i frame
	       */
	      if(last_videofile)
	      {
		if((strcmp(l_videofile, last_videofile) == 0)
		&& (l_video_frame_nr == last_video_frame_nr +1))
		{
                  last_video_frame_nr = l_video_frame_nr;
		  last_fetch_was_compressed_chunk = TRUE;

		  if(gap_debug)
		  {
	            printf("P,");
	            // printf(" Reuse P-FRAME Chunk  at %06d\n", (int)master_frame_nr);
		  }
                  return(TRUE);
		}
	      }
	    }

	    if ((l_frame_type == GVA_MPGFRAME_B_TYPE)
	    ||  (l_frame_type == GVA_MPGFRAME_P_TYPE))
	    {
	      /* bi-directional predicted frame has dependencies both to 
	       * the previous intra frame or p-frame and to the following i or p-frame.
	       *
	       * can use that frame if fetch sequence contains previous i frame
	       * and fetch will continue until the next i or p frame.
	       *
	       * we do a simplified check if the next few (say 3) frames in storyboard sequence
	       * will fetch the next (3) frames in videofile sequence from the same videofile.
	       * this is just a guess, but maybe sufficient in most cases.
	       */
	      if(last_videofile)
	      {
                gboolean l_bframe_ok;
		
                l_bframe_ok = TRUE;  /* assume that B-frame can be used */
		
		if((strcmp(l_videofile, last_videofile) == 0)
		&& (l_video_frame_nr == last_video_frame_nr +1))
		{
		  if(master_frame_nr + GAP_MPEG_ASSUMED_REFERENCE_DISTANCE > max_master_frame_nr)
		  {
		    /* never deliver B-frame at the last few frames in the output video.
		     * (unresolved references to following p or i frames of the
		     *  input video could be the result)
		     */
		    l_bframe_ok = FALSE;
		  }
		  else
		  {
		    gint ii;
		    gint32 l_next_video_frame_nr;
		    char  *l_next_videofile;

		    /* look ahead if the next few fetches in storyboard sequence
		     * will deliver the next frames from the same inputvideo
		     * in ascending input_video sequence at stepsize 1
		     * (it is assumed that the referenced P or I frame
		     *  will be fetched in later calls then)
		     */
		    for(ii=1; ii <= GAP_MPEG_ASSUMED_REFERENCE_DISTANCE; ii++)
		    {
		      l_next_videofile = p_check_chunk_fetch_possible(vidhand
                		    , (master_frame_nr + ii)
                		    , vid_width
                		    , vid_height
                		    , &l_next_video_frame_nr
		                    , &l_frn_elem_2
                		    );
		      if(l_next_videofile)
		      {
        		if((strcmp(l_next_videofile, l_videofile) != 0)
        		|| (l_next_video_frame_nr != l_video_frame_nr +ii))
        		{
        		  l_bframe_ok = FALSE;
        		}
			g_free(l_next_videofile);
		      }
		      else
		      {
        		l_bframe_ok = FALSE;
 		      }
		      if(!l_bframe_ok)
		      {
		        break;
		      }

		    }  /* end for loop (look ahed next few frames in storyboard sequence) */
		  }
		    
		  if(gap_debug)
		  {
		    if(l_bframe_ok) printf("Look Ahead B-FRAME OK to copy\n");
		    else            printf("Look Ahead B-FRAME dont USE\n");
		  }
		
		  if(l_bframe_ok)
		  {
                    last_video_frame_nr = l_video_frame_nr;
		    last_fetch_was_compressed_chunk = TRUE;

		    if(gap_debug)
		    {
		      if (l_frame_type == GVA_MPGFRAME_B_TYPE)
		      {
	                printf("B,");
		      }
		      else
		      {
                        printf("p,");
		      }
	              //printf(" Reuse B-FRAME Chunk  at %06d\n", (int)master_frame_nr);
		    }
                    return(TRUE);
		  }
		}
	      }
	    }
    
            if(gap_debug)
	    {
	      printf("** sorry, no reuse of fetched CHUNK type: %d (1=I/2=P/3=B)  frame_nr:%d (last_frame_nr:%d)\n"
	            ,(int)l_frame_type
		    ,(int)l_video_frame_nr
		    ,(int)last_video_frame_nr
		    );
	    }
	    
	    
	    if((l_frame_type != GVA_MPGFRAME_I_TYPE)
	    && (l_frame_type != GVA_MPGFRAME_P_TYPE)
	    && (l_frame_type != GVA_MPGFRAME_B_TYPE))
	    {
	      printf("** WARNING, unsupported frame_type: %d (supported are: 1=I/2=P/3=B) file:%s  frame_nr:%d (last_frame_nr in the video:%d)\n"
	            ,(int)l_frame_type
		    ,l_videofile
		    ,(int)l_video_frame_nr
		    ,(int)last_video_frame_nr
		    );
	    }
	   
	    last_fetch_was_compressed_chunk = FALSE;
	    last_intra_frame_fetched = FALSE;
            l_videofile = NULL;

          }
	  else
	  {
            if(gap_debug)
	    {
	      printf("**# sorry, no reuse fetch failed  frame_nr:%d (last_frame_nr:%d)\n"
		    ,(int)l_video_frame_nr
		    ,(int)last_video_frame_nr
		    );
	    }
	    last_fetch_was_compressed_chunk = FALSE;
	    last_intra_frame_fetched = FALSE;
            *video_frame_chunk_size = 0;
            return(FALSE);
	  }
        }
      }
    }

  }   /* end IF dont_recode_flag */

  if(last_fetch_was_compressed_chunk)
  {
    *force_keyframe = TRUE;
  }
  
  if(l_videofile_name)
  {
    g_free(l_videofile_name);
  }

  if(l_videofile == NULL)
  {
    last_video_frame_nr = -1;
    last_intra_frame_fetched = FALSE;
    last_fetch_was_compressed_chunk = FALSE;
    if(last_videofile)
    {
      g_free(last_videofile);
    }
    last_videofile = l_videofile;


    if(gap_debug)
    {
       printf("gap_story_render_fetch_composite_image_or_chunk:  CHUNK fetch not possible (doing frame fetch instead)\n");
    }

    *video_frame_chunk_size = 0;
    *image_id = gap_story_render_fetch_composite_image(vidhand
                    , master_frame_nr  /* starts at 1 */
                    , vid_width       /* desired Video Width in pixels */
                    , vid_height      /* desired Video Height in pixels */
                    , filtermacro_file  /* NULL if no filtermacro is used */
                    , layer_id        /* output: Id of the only layer in the composite image */
                    );
    if(*image_id >= 0)
    {
      return(TRUE);
    }
  }
  else
  {
    /*if(gap_debug)*/
    {
      printf("### INTERNAL ERROR at gap_story_render_fetch_composite_image_or_chunk  frame_nr:%d (last_frame_nr:%d)\n"
	    ,(int)l_video_frame_nr
	    ,(int)last_video_frame_nr
	    );
    }
  }

  return(FALSE);

} /* end gap_story_render_fetch_composite_image_or_chunk */



/* ----------------------------------------------------
 * gap_story_render_fetch_composite_image
 * ----------------------------------------------------
 * fetch composite VIDEO Image at a given master_frame_nr
 * within a storyboard framerange list.
 *
 * the returned image is flattend RGB and scaled to
 * desired video framesize.
 *
 *  it is a merged result of all video tracks,
 *
 *  frames at master_frame_nr were loaded
 *  for all video tracks and added to the composite image
 *   (track 0 on top, track N on bottom
 *    of the layerstack)
 *  opacity, scaling and move (decenter) attributes
 *  were set to according to current Video Attributes.
 *
 * an (optional) filtermacro_file is performed on the
 * composite image.
 *  (filtermacros are not supported by the official GIMP-1.2.2
 *   you may need patched GIMP/GAP Sourcecode to use that feature)
 *
 *
 * (simple animations without a storyboard file
 *  are represented by a short storyboard framerange list that has
 *  just one element entry at track 1).
 *
 * return image_id of resulting image and the flattened resulting layer_id
 */
gint32
gap_story_render_fetch_composite_image(GapStoryRenderVidHandle *vidhand
                    , gint32 master_frame_nr  /* starts at 1 */
                    , gint32  vid_width       /* desired Video Width in pixels */
                    , gint32  vid_height      /* desired Video Height in pixels */
                    , char *filtermacro_file  /* NULL if no filtermacro is used */
                    , gint32 *layer_id        /* output: Id of the only layer in the composite image */
                 )
{
  gint    l_track;
  gint32    l_track_min;
  gint32    l_track_max;
  gchar  *l_framename;
  gdouble l_opacity;
  gdouble l_scale_x;
  gdouble l_scale_y;
  gdouble l_move_x;
  gdouble l_move_y;
  GapStoryRenderFrameRangeElem *l_frn_elem;

  gint32        l_comp_image_id;
  gint32        l_tmp_image_id;
  gint32        l_layer_id;
  gint          l_nlayers;
  gint32       *l_layers_list;
  gint32        l_localframe_index;
  gint32        l_local_stepcount;
  gboolean      l_keep_proportions;
  gboolean      l_fit_width;
  gboolean      l_fit_height;
  GapStoryRenderFrameType   l_frn_type;
  char            *l_trak_filtermacro_file;
  gdouble l_red_f;
  gdouble l_green_f;
  gdouble l_blue_f;
  gdouble l_alpha_f;


  l_comp_image_id   = -1;
  l_tmp_image_id    = -1;
  l_layer_id        = -1;
  *layer_id         = -1;

  if(gap_debug)
  {
    printf("gap_story_render_fetch_composite_image START  master_frame_nr:%d  %dx%d\n"
        , (int)master_frame_nr
        , (int)vid_width
        , (int)vid_height
        );
  }

  if(gap_debug)
  {
    if((vidhand->is_mask_handle == FALSE)
    && (master_frame_nr == 1))
    {
      printf("\n###\n###\nSTART rendering at master_frame_nr 1 with this list od elements:\n");
      gap_story_render_debug_print_framerange_list(vidhand->frn_list, -1);
    }
  }

   p_find_min_max_vid_tracknumbers(vidhand->frn_list, &l_track_min, &l_track_max);


  /* reverse order, has the effect, that track 0 is processed as last track
   * and will be put on top of the layerstack
   */
  for(l_track = MIN(GAP_STB_MAX_VID_INTERNAL_TRACKS, l_track_max); l_track >= MAX(0, l_track_min); l_track--)
  {
    l_framename = p_fetch_framename(vidhand->frn_list
                 , master_frame_nr /* starts at 1 */
                 , l_track
                 , &l_frn_type
                 , &l_trak_filtermacro_file
                 , &l_localframe_index   /* used only for ANIMIMAGE and Videoframe Number, -1 for all other types */
                 , &l_local_stepcount    /* nth frame within this clip (starts with 1) */
                 , &l_keep_proportions
                 , &l_fit_width
                 , &l_fit_height
                 , &l_red_f
                 , &l_green_f
                 , &l_blue_f
                 , &l_alpha_f
                 , &l_opacity       /* output opacity 0.0 upto 1.0 */
                 , &l_scale_x       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                 , &l_scale_y       /* output 0.0 upto 10.0 where 1.0 is 1:1 */
                 , &l_move_x        /* output -1.0 upto 1.0 where 0.0 is centered */
                 , &l_move_y        /* output -1.0 upto 1.0 where 0.0 is centered */
                 , &l_frn_elem      /* output selected to the relevant framerange element */
                 );

     if((l_framename) || (l_frn_type == GAP_FRN_COLOR))
     {
       if(l_frn_type == GAP_FRN_COLOR)
       {
           l_tmp_image_id = p_create_unicolor_image(&l_layer_id
                                                , vid_width
                                                , vid_height
                                                , l_red_f
                                                , l_green_f
                                                , l_blue_f
                                                , l_alpha_f
                                                );

       }
       else
       {
         if(l_framename)
         {
           if((l_frn_type == GAP_FRN_ANIMIMAGE)
           || (l_frn_type == GAP_FRN_IMAGE))
           {
             gint32 l_orig_image_id;

             l_orig_image_id = p_load_cache_image(l_framename);
             gimp_selection_none(l_orig_image_id);
             if(l_frn_type == GAP_FRN_IMAGE)
             {
               l_layer_id = p_prepare_RGB_image(l_orig_image_id);
               l_tmp_image_id = gimp_image_duplicate(l_orig_image_id);
             }
             else
             {
               /* GAP_FRN_ANIMIMAGE */
               if(gap_debug)
               {
                 printf("ANIM fetch  l_localframe_index: %d master:%d  from: %d to: %d\n"
                   ,(int)l_localframe_index 
                   ,(int)master_frame_nr
                   ,(int)l_frn_elem->frame_from
                   ,(int)l_frn_elem->frame_to
                   );
               }

               l_tmp_image_id = p_create_unicolor_image(&l_layer_id
                                                       , gimp_image_width(l_orig_image_id)
                                                       , gimp_image_height(l_orig_image_id)
                                                       , 0.0, 0.0, 0.0, 0.0);
               gimp_layer_add_alpha(l_layer_id);
               l_layers_list = gimp_image_get_layers(l_orig_image_id, &l_nlayers);
               if(l_layers_list != NULL)
               {
                  if((l_localframe_index < l_nlayers)
                  && (l_localframe_index >= 0))
                  {
                     gint32 l_fsel_layer_id;

                     if(gap_debug)
                     {
                       printf("ANIM-IMG: layer_id: %d gimp_layer_get_apply_mask:%d\n"
                          ,(int)l_layers_list[l_localframe_index]
                          ,(int)gimp_layer_get_apply_mask(l_layers_list[l_localframe_index])
                          );
                     }


                     gimp_drawable_set_visible(l_layers_list[l_localframe_index], TRUE);
                     if (0 != gimp_layer_get_apply_mask(l_layers_list[l_localframe_index]))
                     {
                       /* the layer has an active mask, apply the mask now
                        * because copying from the layer ignores the mask
                        */
                       gimp_layer_remove_mask(l_layers_list[l_localframe_index], GIMP_MASK_APPLY);
                     }
                     gimp_layer_resize_to_image_size(l_layers_list[l_localframe_index]);
                     gimp_edit_copy(l_layers_list[l_localframe_index]);
                     l_fsel_layer_id = gimp_edit_paste(l_layer_id, FALSE);  /* FALSE paste clear selection */
                     gimp_floating_sel_anchor(l_fsel_layer_id);
                  }
                  g_free (l_layers_list);
               }
             }
           }
           else
           {
             if(l_frn_type == GAP_FRN_MOVIE)
             {
               l_tmp_image_id = -1;

               /* fetch frame from a videofile (l_framename contains the videofile name) */
               if(l_frn_elem->gvahand == NULL)
               {
                  /* before we open a new GVA videohandle, lets check
                   * if another element has already opened this videofile,
                   * and reuse the already open gvahand handle if possible
                   */
                  l_frn_elem->gvahand = p_try_to_steal_gvahand(vidhand
                                                              , master_frame_nr
                                                              , l_frn_elem->basename
                                                              , l_frn_elem->exact_seek
                                                              );
                  if(l_frn_elem->gvahand == NULL)
                  {
                    if(vidhand->preferred_decoder)
                    {
                      l_frn_elem->gvahand = GVA_open_read_pref(l_framename
                                             , l_frn_elem->seltrack
                                             , 1 /* aud_track */
                                             , vidhand->preferred_decoder
                                             , FALSE  /* use MMX if available (disable_mmx == FALSE) */
                                             );
                    }
                    else
                    {
                      l_frn_elem->gvahand = GVA_open_read(l_framename
                                                        ,l_frn_elem->seltrack
                                                        ,1 /* aud_track */
                                                        );
                    }

                    if(l_frn_elem->gvahand)
                    {
                      GVA_set_fcache_size(l_frn_elem->gvahand, GAP_STB_RENDER_GVA_FRAMES_TO_KEEP_CACHED);

                      l_frn_elem->gvahand->do_gimp_progress = vidhand->do_gimp_progress;
                      if(l_frn_elem->exact_seek == 1)
                      {
                        /* configure the GVA Procedures for exact (but slow) seek emulaion */
                        l_frn_elem->gvahand->emulate_seek = TRUE;
                      }
                    }
                  }


               }

               if(l_frn_elem->gvahand)
               {
                  gint32 l_deinterlace;
                  gdouble l_threshold;
                  t_GVA_RetCode  l_fcr;

                  /* split delace value: integer part is deinterlace mode, rest is threshold */
                  l_deinterlace = l_frn_elem->delace;
                  l_threshold = l_frn_elem->delace - (gdouble)l_deinterlace;

                  /* set image and layer in the gvahand structure invalid,
                   * to force creation of a new image in the following call of  GVA_frame_to_gimp_layer
                   */
                  l_frn_elem->gvahand->image_id = -1;
                  l_frn_elem->gvahand->layer_id = -1;


                  /* attempt to read frame from the GVA API internal framecache */

                  /* printf("\nST: before  GVA_debug_print_fcache (2) #:%d\n", (int)l_localframe_index );
                   * GVA_debug_print_fcache(l_frn_elem->gvahand);
                   * printf("ST: before  GVA_frame_to_gimp_layer (2) attempt cache read  #:%d\n", (int)l_localframe_index );
                   */

                  l_fcr = GVA_frame_to_gimp_layer(l_frn_elem->gvahand
                                    , TRUE                 /* delete_mode */
                                    , l_localframe_index   /* framenumber */
                                    , l_deinterlace
                                    , l_threshold
                                    );

                  if (l_fcr != GVA_RET_OK)
                  {
                    /* if no success, we try explicite read that frame  */
                    if(l_frn_elem->gvahand->current_seek_nr != l_localframe_index)
                    {
                      if(((l_frn_elem->gvahand->current_seek_nr + GAP_STB_RENDER_GVA_FRAMES_TO_KEEP_CACHED) > l_localframe_index)
                      &&  (l_frn_elem->gvahand->current_seek_nr < l_localframe_index ) )
                      {
                        /* near forward seek is performed by dummyreads to fill up the framecache
                         */
                        while(l_frn_elem->gvahand->current_seek_nr < l_localframe_index)
                        {
                          GVA_get_next_frame(l_frn_elem->gvahand);
                        }
                      }
                      else
                      {
                        if(vidhand->do_gimp_progress)
                        {
                           gimp_progress_init(_("Seek Inputvideoframe..."));
                        }
                        GVA_seek_frame(l_frn_elem->gvahand, (gdouble)l_localframe_index, GVA_UPOS_FRAMES);
                        if(vidhand->do_gimp_progress)
                        {
                           gimp_progress_init(_("Continue Encoding..."));
                        }
                     }
                    }

                    if(GVA_get_next_frame(l_frn_elem->gvahand) == GVA_RET_OK)
                    {
                      GVA_frame_to_gimp_layer(l_frn_elem->gvahand
                                      , TRUE   /* delete_mode */
                                      , l_localframe_index   /* framenumber */
                                      , l_deinterlace
                                      , l_threshold
                                      );
                    }
                  }
                  /* take the newly created image from gvahand stucture */
                  l_tmp_image_id = l_frn_elem->gvahand->image_id;
                  l_frn_elem->gvahand->image_id = -1;
                  l_frn_elem->gvahand->layer_id = -1;
               }
             }
             else
             {
               /* GAP_FRN_FRAMES
                * (l_framename  is one single imagefile out of a series of numbered imagefiles)
                */
               if(gap_debug)
               {
                 printf("FRAME fetch l_framename: %s\n    ===> master:%d  from: %d to: %d\n"
                   ,l_framename
                   ,(int)master_frame_nr
                   ,(int)l_frn_elem->frame_from
                   ,(int)l_frn_elem->frame_to
                   );
               }
               l_tmp_image_id = gap_lib_load_image(l_framename);
             }
           }
           g_free(l_framename);
           if(l_tmp_image_id < 0)
           {
              return -1;
           }
           l_layer_id = p_prepare_RGB_image(l_tmp_image_id);
         }
       }


       if(gap_debug) printf("p_prepare_RGB_image returned layer_id: %d, tmp_image_id:%d\n", (int)l_layer_id, (int)l_tmp_image_id);

       if(l_comp_image_id  < 0)
       {
         if((l_opacity == 1.0)
         && (l_scale_x == 1.0)
         && (l_scale_y == 1.0)
         && (l_move_x == 0.0)
         && (l_move_y == 0.0)
         && (l_fit_width)
         && (l_fit_height)
         && (!l_keep_proportions)
         && (l_frn_elem->flip_request == GAP_STB_FLIP_NONE)
         && (l_frn_elem->mask_name == NULL)
         && (l_trak_filtermacro_file == NULL)
         && (l_frn_type != GAP_FRN_ANIMIMAGE)
         )
         {
           /* because there are no transformations in the first handled track,
            * we can save time and directly use the loaded tmp image as base for the composite image
            */
           l_comp_image_id = l_tmp_image_id;


           /* scale image to desired Videosize */
           if ((gimp_image_width(l_comp_image_id) != vid_width)
           ||  (gimp_image_height(l_comp_image_id) != vid_height) )
           {
              if(gap_debug) printf("DEBUG: gap_story_render_fetch_composite_image scaling composite image\n");
              gimp_image_scale(l_comp_image_id, vid_width, vid_height);
           }
         }
         else
         {
           /* create empty backgound */
           gint32 l_empty_layer_id;
           l_comp_image_id = p_create_unicolor_image(&l_empty_layer_id
                                , vid_width
                                , vid_height
                                , 0.0
                                , 0.0
                                , 0.0
                                , 1.0
                                );
         }
       }

       if(l_tmp_image_id != l_comp_image_id)
       {
         p_transform_and_add_layer(l_comp_image_id, l_tmp_image_id, l_layer_id
                                  ,l_keep_proportions
                                  ,l_fit_width
                                  ,l_fit_height
                                  ,l_opacity
                                  ,l_scale_x
                                  ,l_scale_y
                                  ,l_move_x
                                  ,l_move_y
                                  ,l_trak_filtermacro_file
                                  ,l_frn_elem->flip_request
                                  ,l_frn_elem
                                  ,vidhand
                                  ,l_local_stepcount
                                   );
         gap_image_delete_immediate(l_tmp_image_id);
       }

     }
  }       /* end for loop over all video tracks */

  if(l_comp_image_id  < 0)
  {
    /* none of the tracks had a frame image on this master_frame_nr position
     * create a blank image (VID_SILENNCE)
     */
    l_comp_image_id = p_create_unicolor_image(&l_layer_id
                         , vid_width
                         , vid_height
                         , 0.0
                         , 0.0
                         , 0.0
                         , 1.0
                         );
  }

  /* debug: disabled code to display a copy of the image */
  if(1==0)
  {
    p_debug_dup_image(l_comp_image_id);
  }


  if(vidhand->is_mask_handle == TRUE)
  {
    /* we are running as mask fetcher,
     * therefore convert to GRAY image
     */
    if(gimp_image_base_type(l_comp_image_id) != GIMP_GRAY)
    {
      gimp_image_convert_grayscale(l_comp_image_id);
    }
  }

  /* check the layerstack
   */
  l_layers_list = gimp_image_get_layers(l_comp_image_id, &l_nlayers);
  if(l_layers_list != NULL)
  {
    l_layer_id = l_layers_list[0];
    g_free (l_layers_list);
  }


  if(vidhand->is_mask_handle != TRUE)
  {
    /* debug feature: save the multilayer composite frame  
     * before it is passed to the filtermacro
     * (always off for mask fetching)
     */
    p_frame_backup_save(  GAP_VID_ENC_SAVE_MULTILAYER
                      , l_comp_image_id
                      , l_layer_id
                      , master_frame_nr
                      , TRUE               /* can be multilayer */
                      );
  }

  if((l_nlayers > 1 )
  || (gimp_drawable_has_alpha(l_layer_id)))
  {
     if(gap_debug) printf("DEBUG: gap_story_render_fetch_composite_image flatten Composite image\n");

     /* flatten current frame image (reduce to single layer) */
     l_layer_id = gimp_image_flatten (l_comp_image_id);
  }

  /* execute filtermacro (optional if supplied) */
  p_exec_filtermacro(l_comp_image_id
                    , l_layer_id
                    , filtermacro_file
                    );
  /* check again size and scale image to desired Videosize if needed */
  if ((gimp_image_width(l_comp_image_id) != vid_width)
  ||  (gimp_image_height(l_comp_image_id) != vid_height) )
  {
     if(gap_debug) printf("DEBUG: gap_story_render_fetch_composite_image: scaling tmp image\n");

     gimp_image_scale(l_comp_image_id, vid_width, vid_height);
  }

  /* check again for layerstack (macro could have add more layers)
   * or there might be an alpha channel
   */
  l_layers_list = gimp_image_get_layers(l_comp_image_id, &l_nlayers);
  if(l_layers_list != NULL)
  {
    l_layer_id = l_layers_list[0];
    g_free (l_layers_list);
  }
  if((l_nlayers > 1 )
  || (gimp_drawable_has_alpha(l_layer_id)))
  {
     if(gap_debug) printf("DEBUG: gap_story_render_fetch_composite_image  FINAL flatten Composite image\n");

      /* flatten current frame image (reduce to single layer) */
      l_layer_id = gimp_image_flatten (l_comp_image_id);
  }


  *layer_id =l_layer_id;

  if(vidhand->is_mask_handle != TRUE)
  {
    /* debug feature: save the flattened composite as jpg frame  before it is passed to the encoder */
    p_frame_backup_save(  GAP_VID_ENC_SAVE_FLAT
                        , l_comp_image_id
                        , l_layer_id
                        , master_frame_nr
                        , FALSE               /* is no multilayer, use jpeg */
                        );

    /* debug feature: monitor composite image while encoding */
    p_encoding_monitor(GAP_VID_ENC_MONITOR
                    , l_comp_image_id
                    , l_layer_id
                    , master_frame_nr
                    );
  }

  if(gap_debug) printf("gap_story_render_fetch_composite_image END  master_frame_nr:%d  image_id:%d layer_id:%d\n", (int)master_frame_nr, (int)l_comp_image_id, (int)*layer_id );

  return(l_comp_image_id);

} /* end gap_story_render_fetch_composite_image */

